<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.269">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Jouni Helske">
<meta name="author" content="Satu Helske">
<meta name="author" content="Mohammed Saqr">
<meta name="author" content="Sonsoles López-Pernas">
<meta name="author" content="Keefe Murphy">
<meta name="keywords" content="Markov models, learning analytics, sequence analysis, transition analysis">

<title>Learning analytics methods and tutorials - 12&nbsp; A Modern Approach to Transition Analysis and Process Mining with Markov Models in Education</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../chapters/ch13-multichannel/ch13-multi.html" rel="next">
<link href="../../chapters/ch11-vasstra/ch11-vasstra.html" rel="prev">
<script src="../../site_libs/cookie-consent/cookie-consent.js"></script>
<link href="../../site_libs/cookie-consent/cookie-consent.css" rel="stylesheet">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-Y4VBV3J9WD"></script>

<script type="text/plain" cookie-consent="tracking">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-Y4VBV3J9WD', { 'anonymize_ip': true});
</script>

<script type="text/javascript" charset="UTF-8">
document.addEventListener('DOMContentLoaded', function () {
cookieconsent.run({
  "notice_banner_type":"simple",
  "consent_type":"implied",
  "palette":"light",
  "language":"en",
  "page_load_consent_levels":["strictly-necessary","functionality","tracking","targeting"],
  "notice_banner_reject_button_hide":false,
  "preferences_center_close_button_hide":false,
  "website_name":""
  });
});
</script> 
  

<link href="../../site_libs/pagedtable-1.1/css/pagedtable.css" rel="stylesheet">
<script src="../../site_libs/pagedtable-1.1/js/pagedtable.js"></script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<meta name="twitter:title" content="Learning analytics methods and tutorials - 12&nbsp; A Modern Approach to Transition Analysis and Process Mining with Markov Models in Education">
<meta name="twitter:description" content="This chapter presents an introduction to Markovian modelling for the analysis of sequence data.">
<meta name="twitter:card" content="summary">
<meta name="citation_title" content="[12]{.chapter-number}&nbsp; [A Modern Approach to Transition Analysis and Process Mining with Markov Models in Education]{.chapter-title}">
<meta name="citation_abstract" content="This chapter presents an introduction to Markovian modelling for the analysis of sequence data. Contrary to the deterministic approach seen in the previous sequence analysis chapters, Markovian models are probabilistic models, focusing on the transitions between states instead of studying sequences as a whole. The chapter provides an introduction to this method and differentiates between its most common variations: first-order Markov models, hidden Markov models, mixture Markov models, and mixture hidden Markov models. In addition to a thorough explanation and contextualisation within the existing literature, the chapter provides a step-by-step tutorial on how to implement each type of Markovian model using the R package `seqHMM`. The chapter also provides a complete guide to performing stochastic process mining with Markovian models as well as plotting, comparing and clustering different process models.">
<meta name="citation_keywords" content="Markov models, learning analytics, sequence analysis, transition analysis">
<meta name="citation_author" content="Jouni Helske">
<meta name="citation_author" content="Satu Helske">
<meta name="citation_author" content="Mohammed Saqr">
<meta name="citation_author" content="Sonsoles López-Pernas">
<meta name="citation_author" content="Keefe Murphy">
<meta name="citation_fulltext_html_url" content="https://lamethods.github.io/ch12-markov.html">
<meta name="citation_language" content="en">
<meta name="citation_reference" content="citation_title=A tutorial on hidden Markov models and selected applications in speech recognition;,citation_author=Lawrence Rabiner;,citation_publication_date=1989;,citation_cover_date=1989;,citation_year=1989;,citation_issue=2;,citation_doi=10.1109/5.18626;,citation_volume=77;,citation_journal_title=Proceedings of the IEEE;,citation_publisher=IEEE;">
<meta name="citation_reference" content="citation_title=dynamite: An R package for dynamic multivariate panel models;,citation_author=Santtu Tikka;,citation_author=Jouni Helske;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://arxiv.org/abs/2302.01607;,citation_doi=10.48550/ARXIV.2302.01607;,citation_publisher=arXiv;">
<meta name="citation_reference" content="citation_title=LMest: An R package for latent Markov models for longitudinal categorical data;,citation_author=Francesco Bartolucci;,citation_author=Silvia Pandolfi;,citation_author=Fulvia Pennoni;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_issue=4;,citation_doi=10.18637/jss.v081.i04;,citation_volume=81;,citation_journal_title=Journal of Statistical Software;">
<meta name="citation_reference" content="citation_title=march: Markov chains;,citation_author=Ogier Maitre;,citation_author=Kevin Emery;,citation_author=undefined Oliver Buschor;,citation_author=Andre Berchtold;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_fulltext_html_url=https://CRAN.R-project.org/package=march;">
<meta name="citation_reference" content="citation_title=The double chain Markov model;,citation_author=Andre Berchtold;,citation_publication_date=1999;,citation_cover_date=1999;,citation_year=1999;,citation_fulltext_html_url=https://doi.org/10.1080/03610929908832439;,citation_issue=11;,citation_doi=10.1080/03610929908832439;,citation_volume=28;,citation_journal_title=Communications in Statistics - Theory and Methods;,citation_publisher=Taylor &amp;amp;amp; Francis;">
<meta name="citation_reference" content="citation_title=The longitudinal association between engagement and achievement varies by time, students’ profiles, and achievement state: A full program study;,citation_abstract=There is a paucity of longitudinal studies in online learning across courses or throughout programs. Our study intends to add to this emerging body of research by analyzing the longitudinal trajectories of interaction between student engagement and achievement over a full four-year program. We use learning analytics and life-course methods to study how achievement and engagement are intertwined and how such relationship evolves over a full program for 106 students. Our findings have indicated that the association between engagement and achievement varies between students and progresses differently between such groups over time. Our results showed that online engagement at any single time-point is not a consistent indicator for high achievement. It takes more than a single point of time to reliably forecast high achievement throughout the program. Longitudinal high grades, or longitudinal high levels of engagement (either separately or combined) were indicators of a stable academic trajectory in which students remained engaged —at least on average— and had a higher level of achievement. On the other hand, disengagement at any time point was consistently associated with lower achievement among low-engaged students. Improving to a higher level of engagement was associated with —at least— acceptable achievement levels and rare dropouts. Lack of improvement or “catching up” may be a more ominous sign that should be proactively addressed.;,citation_author=Mohammed Saqr;,citation_author=Sonsoles López-Pernas;,citation_author=Satu Helske;,citation_author=Stefan Hrastinski;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_volume=199;,citation_journal_title=Computers &amp;amp;amp; Education;">
<meta name="citation_reference" content="citation_title=From variables to states to trajectories (VaSSTra): A method for modelling the longitudinal dynamics of learning and behaviour;,citation_abstract=Research in learning analytics needs longitudinal studies that explore the learner’s behaviour, disposition, and learning practices across time, a gap this article aims to bridge. We present VaSSTra: an innovative method for the longitudinal analysis of educational data that can be applied at different time scales (e.g., days, weeks, or courses), and allows the study of different aspects of learning as well as the factors that explain how such aspects evolve over time. Our method combines life- events methods with sequence analysis and consists of three steps: (1) converting variables to states (where variables are grouped into homogenous states); (2) from states to sequences (where the states are used to construct sequences across time), and (3) from sequences to trajectories (where similar sequences are grouped in trajectories). VaSSTra enables us to map the longitudinal unfolding of events while taking advantage of the wealth of life-events methods to visualize, model and describe the temporal dynamics of longitudinal activities. We demonstrate the method with a practical case study example.;,citation_author=Sonsoles López-Pernas;,citation_author=Mohammed Saqr;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_conference_title=Proceedings of the tenth international conference on technological ecosystems for enhancing multiculturality (TEEM’22);,citation_conference=Springer;">
<meta name="citation_reference" content="citation_title=Intense, turbulent, or wallowing in the mire: A longitudinal study of cross-course online tactics, strategies, and trajectories;,citation_abstract=Research has repeatedly demonstrated that students with effective learning strategies are more likely to have better academic achievement. Existing research has mostly focused on a single course or two, while longitudinal studies remain scarce. The present study examines the longitudinal sequence of students’ strategies, their succession, consistency, temporal unfolding, and whether students tend to retain or adapt strategies between courses. We use a large dataset of online traces from 135 students who completed 10 successive courses (i.e., 1350 course enrollments) in a higher education program. The methods used in this study have shown the feasibility of using trace data recorded by learning management systems to unobtrusively trace and model the longitudinal learning strategies across a program. We identified three program-level strategy trajectories: a stable and intense trajectory related to deep learning where students used diverse strategies and scored the highest grades; a fluctuating interactive trajectory, where students focused on course requirements, scored average grades, and were relatively fluctuating; and a light trajectory related to surface learning where students invested the least effort, scored the lowest grades, and had a relatively stable pathway. Students who were intensely active were more likely to transfer the intense strategies and therefore, they were expected to require less support or guidance. Students focusing on course requirements were not as effective self-regulators as they seemed and possibly required early guidance and support from teachers. Students with consistent light strategies or low effort needed proactive guidance and support.;,citation_author=Mohammed Saqr;,citation_author=Sonsoles López-Pernas;,citation_author=Jelena Jovanović;,citation_author=Dragan Gašević;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_volume=57;,citation_journal_title=The Internet and Higher Education;">
<meta name="citation_reference" content="citation_title=How CSCL roles emerge, persist, transition, and evolve over time: A four-year longitudinal study;,citation_author=Mohammed Saqr;,citation_author=Sonsoles López-Pernas;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_volume=189;,citation_journal_title=Computers &amp;amp;amp; Education;">
<meta name="citation_reference" content="citation_title=Bringing synchrony and clarity to complex multi-channel data: A learning analytics study in programming education;,citation_abstract=Supporting teaching and learning programming with learning analytics is an active area of inquiry. Most data used for learning analytics research comes from learning management …;,citation_author=Sonsoles López-Pernas;,citation_author=Mohammed Saqr;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_volume=9;,citation_journal_title=IEEE Access;,citation_publisher=ieeexplore.ieee.org;">
<meta name="citation_reference" content="citation_title=The longitudinal trajectories of online engagement over a full program;,citation_abstract=Student engagement has a trajectory (a timeline) that unfolds over time and can be shaped by different factors including learners’ motivation, school conditions, and the nature of …;,citation_author=Mohammed Saqr;,citation_author=Sonsoles López-Pernas;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_volume=175;,citation_journal_title=Computers &amp;amp;amp; Education;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=The dire cost of early disengagement: A four-year learning analytics study over a full program;,citation_author=Mohammed Saqr;,citation_author=Sonsoles López-Pernas;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_inbook_title=Technology-Enhanced learning for a free, safe, and sustainable world;,citation_series_title=Lecture notes in computer science;">
<meta name="citation_reference" content="citation_title=BBmisc: Miscellaneous helper functions for B. Bischl;,citation_author=Bernd Bischl;,citation_author=Michel Lang;,citation_author=Jakob Bossek;,citation_author=Daniel Horn;,citation_author=Jakob Richter;,citation_author=Dirk Surmann;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://CRAN.R-project.org/package=BBmisc;">
<meta name="citation_reference" content="citation_title=tidyLPA: An R package to easily carry out latent profile analysis (LPA) using open-source or commercial software;,citation_author=Joshua M. Rosenberg;,citation_author=Patrick N. Beymer;,citation_author=Daniel J. Anderson;,citation_author=Caspar J. Van Lissa;,citation_author=Jennifer A. Schmidt;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_fulltext_html_url=https://joss.theoj.org/papers/10.21105/joss.00978;,citation_issue=30;,citation_doi=10.21105/joss.00978;,citation_volume=3;,citation_journal_title=Journal of Open Source Software;">
<meta name="citation_reference" content="citation_title=Analyzing and visualizing state sequences in R with TraMineR;,citation_author=Alexis Gabadinho;,citation_author=Gilbert Ritschard;,citation_author=Nicolas S. Müller;,citation_author=Matthias Studer;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_fulltext_html_url=https://doi.org/10.18637/jss.v040.i04;,citation_issue=4;,citation_doi=10.18637/jss.v040.i04;,citation_volume=40;,citation_journal_title=Journal of Statistical Software;,citation_publisher=Foundation for Open Access Statistic;">
<meta name="citation_reference" content="citation_title=seqhandbook: Miscellaneous tools for sequence analysis;,citation_author=Nicolas Robette;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://CRAN.R-project.org/package=seqhandbook;">
<meta name="citation_reference" content="citation_title=Mixture hidden Markov models for sequence data: The seqHMM package in R;,citation_author=Satu Helske;,citation_author=Jouni Helske;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_fulltext_html_url=https://doi.org/10.18637/jss.v088.i03;,citation_issue=3;,citation_doi=10.18637/jss.v088.i03;,citation_volume=88;,citation_journal_title=Journal of Statistical Software;,citation_publisher=Foundation for Open Access Statistic;">
<meta name="citation_reference" content="citation_title=Gmisc: Descriptive statistics, transition plots, and more;,citation_author=Max Gordon;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://CRAN.R-project.org/package=Gmisc;">
<meta name="citation_reference" content="citation_title=WeightedCluster library manual: A practical guide to creating typologies of trajectories in the social sciences with R;,citation_author=Matthias Studer;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_fulltext_html_url=https://www.centre-lives.ch/fr/bibcite/reference/84;,citation_doi=10.12682/LIVES.2296-1658.2013.24;,citation_journal_title=LIVES;">
<meta name="citation_reference" content="citation_title=Analyzing state sequences with probabilistic suffix trees: The PST R package;,citation_author=Alexis Gabadinho;,citation_author=Gilbert Ritschard;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_issue=3;,citation_doi=10.18637/jss.v072.i03;,citation_volume=72;,citation_journal_title=Journal of Statistical Software;">
<meta name="citation_reference" content="citation_title=Sequence analysis: Its past, present, and future;,citation_author=Tim F. Liao;,citation_author=Danilo Bolano;,citation_author=Christian Brzinsky-Fay;,citation_author=Benjamin Cornwell;,citation_author=Anette Eva Fasang;,citation_author=Satu Helske;,citation_author=Raffaella Piccarreta;,citation_author=Marcel Raab;,citation_author=Gilbert Ritschard;,citation_author=Emanuela Struffolino;,citation_author=Matthias Studer;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://doi.org/10.1016/j.ssresearch.2022.102772;,citation_doi=10.1016/j.ssresearch.2022.102772;,citation_volume=107;,citation_journal_title=Social Science Research;,citation_publisher=Elsevier BV;">
<meta name="citation_reference" content="citation_title=Modeling the dynamics of longitudinal processes in education. A tutorial with r for the VaSSTra method;,citation_author=Sonsoles López-Pernas;,citation_author=Mohammed Saqr;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_inbook_title=Learning analytics methods and tutorials: A practical guide using R;">
<meta name="citation_reference" content="citation_title=Mixed Markov latent class models;,citation_author=Frank Pol;,citation_author=Rolf Langeheine;,citation_publication_date=1990;,citation_cover_date=1990;,citation_year=1990;,citation_fulltext_html_url=https://doi.org/10.2307/271087;,citation_doi=10.2307/271087;,citation_volume=20;,citation_journal_title=Sociological Methodology;,citation_publisher=JSTOR;">
<meta name="citation_reference" content="citation_title=Latent class models in longitudinal research;,citation_author=J. K. Vermunt;,citation_author=B. Tran;,citation_author=J. Magidson;,citation_editor=S. Menard;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_isbn=9780123704818;,citation_inbook_title=Handbook of longitudinal research;">
<meta name="citation_reference" content="citation_title=Estimating the dimension of a model;,citation_author=Gideon E Schwarz;,citation_publication_date=1978;,citation_cover_date=1978;,citation_year=1978;,citation_issue=2;,citation_doi=10.1214/aos/1176344136;,citation_volume=6;,citation_journal_title=The Annals of Statistics;,citation_publisher=The Institute of Mathematical Statistics;">
<meta name="citation_reference" content="citation_title=qgraph: network visualizations of relationships in psychometric data;,citation_author=Sacha Epskamp;,citation_author=Angélique O. J. Cramer;,citation_author=Lourens J. Waldorp;,citation_author=Verena D. Schmittmann;,citation_author=Danny Borsboom;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_issue=4;,citation_volume=48;,citation_journal_title=Journal of Statistical Software;">
<meta name="citation_reference" content="citation_title=rio: a Swiss-army knife for data file I/O;,citation_author=Chung-hong Chan;,citation_author=Geoffrey CH Chan;,citation_author=Thomas J. Leeper;,citation_author=Jason Becker;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;">
<meta name="citation_reference" content="citation_title=seqHMM: Mixture hidden Markov models for social sequence data and other multivariate, multichannel categorical time series;,citation_author=Jouni Helske;,citation_author=Satu Helske;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://cran.r-project.org/package=seqHMM;">
<meta name="citation_reference" content="citation_title=Welcome to the tidyverse;,citation_author=Hadley Wickham;,citation_author=Mara Averick;,citation_author=Jennifer Bryan;,citation_author=Winston Chang;,citation_author=Lucy D’Agostino McGowan;,citation_author=Romain François;,citation_author=Garrett Grolemund;,citation_author=Alex Hayes;,citation_author=Lionel Henry;,citation_author=Jim Hester;,citation_author=Max Kuhn;,citation_author=Thomas Lin Pedersen;,citation_author=Evan Miller;,citation_author=Stephan Milton Bache;,citation_author=Kirill Müller;,citation_author=Jeroen Ooms;,citation_author=David Robinson;,citation_author=Dana Paige Seidel;,citation_author=Vitalie Spinu;,citation_author=Kohske Takahashi;,citation_author=Davis Vaughan;,citation_author=Claus Wilke;,citation_author=Kara Woo;,citation_author=Hiroaki Yutani;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_issue=43;,citation_doi=10.21105/joss.01686;,citation_volume=4;,citation_journal_title=Journal of Open Source Software;">
<meta name="citation_reference" content="citation_title=Guide for Latent GOLD 5.1: Basic, Advanced, and Syntax;,citation_author=J. K. Vermunt;,citation_author=J. Magidson;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_technical_report_institution=Statistical Innovations Inc.;">
<meta name="citation_reference" content="citation_title=Mplus User’s Guide;,citation_author=L. K. Muthén;,citation_author=Muthén B. O.;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;">
<meta name="citation_reference" content="citation_title=How CSCL roles emerge, persist, transition, and evolve over time: A four-year longitudinal study;,citation_author=Mohammed Saqr;,citation_author=Sonsoles López-Pernas;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://www.sciencedirect.com/science/article/pii/S036013152200152X;,citation_doi=https://doi.org/10.1016/j.compedu.2022.104581;,citation_issn=0360-1315;,citation_volume=189;,citation_journal_title=Computers &amp;amp;amp; Education;">
<meta name="citation_reference" content="citation_title=Multichannel sequence analysis in educational research using r;,citation_author=Sonsoles López-Pernas;,citation_author=Keefe Murphy;,citation_author=Mohammed Saqr;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_inbook_title=Learning analytics methods and tutorials: A practical guide using R;">
<meta name="citation_reference" content="citation_title=Sequence analysis in education: Principles, technique, and tutorial with r;,citation_author=Mohammed Saqr;,citation_author=Sonsoles López-Pernas;,citation_author=Satu Helske;,citation_author=Marion Durand;,citation_author=Keefe Murphy;,citation_author=Matthias Studer;,citation_author=Gilbert Ritschard;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_inbook_title=Learning analytics methods and tutorials: A practical guide using R;">
<meta name="citation_reference" content="citation_title=Combining sequence analysis and hidden markov models in the analysis of complex life sequence data;,citation_author=Satu Helske;,citation_author=Jouni Helske;,citation_author=Mervi Eerola;,citation_editor=Gilbert Ritschard;,citation_editor=Matthias Studer;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_doi=10.1007/978-3-319-95420-2\_11;,citation_isbn=978-3-319-95420-2;,citation_inbook_title=Sequence analysis and related approaches: Innovative methods and applications;">
<meta name="citation_reference" content="citation_title=Mplus: A general latent variable modeling program;,citation_author=Bengt Muthén;,citation_author=Linda Muthén;,citation_fulltext_html_url=https://www.statmodel.com/download/Mplus-A\%20General\%20Latent\%20Variable\%20Modeling\%20Program.pdf;">
<meta name="citation_reference" content="citation_title=A person-centered approach to study students’ socio-emotional interaction profiles and regulation of collaborative learning;,citation_author=Törmänen;,citation_author=Järvenoja;,citation_author=Saqr;,citation_author=Malmberg;,citation_author=others;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_issn=2504-284X;,citation_journal_title=Frontiers in Education;">
<meta name="citation_reference" content="citation_title=Affective states and regulation of learning during socio-emotional interactions in secondary school collaborative groups;,citation_author=Tiina Törmänen;,citation_author=Hanna Järvenoja;,citation_author=Mohammed Saqr;,citation_author=Jonna Malmberg;,citation_author=Sanna Järvelä;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_issue=S1;,citation_doi=10.1111/bjep.12525;,citation_issn=0007-0998, 2044-8279;,citation_pmid=35748024;,citation_volume=93 Suppl 1;,citation_journal_title=British Journal of Educational Psychology;,citation_publisher=Wiley;">
<meta name="citation_reference" content="citation_title=From study tactics to learning strategies: An analytical method for extracting interpretable representations;,citation_author=Ed Fincham;,citation_author=Dragan Gašević;,citation_author=Jelena Jovanović;,citation_author=Abelardo Pardo;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_issue=1;,citation_doi=10.1109/TLT.2018.2823317;,citation_issn=1939-1382;,citation_volume=12;,citation_journal_title=IEEE Transactions on Learning Technologies.;">
<meta name="citation_reference" content="citation_title=Applying learning analytics to map students’ self-regulated learning tactics in an academic writing course;,citation_author=Ward Peeters;,citation_author=Mohammed Saqr;,citation_author=Olga Viberg;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_volume=1;,citation_conference_title=Proceedings of the 28th international conference on computers in education;">
<meta name="citation_reference" content="citation_title=Effects of real-time analytics-based personalized scaffolds on students’ self-regulated learning;,citation_author=Lyn Lim;,citation_author=Maria Bannert;,citation_author=Joep Graaf;,citation_author=Shaveen Singh;,citation_author=Yizhou Fan;,citation_author=Surya Surendrannair;,citation_author=Mladen Rakovic;,citation_author=Inge Molenaar;,citation_author=Johanna Moore;,citation_author=Dragan Gašević;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://www.sciencedirect.com/science/article/pii/S0747563222003673;,citation_issue=107547;,citation_doi=10.1016/j.chb.2022.107547;,citation_issn=0747-5632, 1873-7692;,citation_volume=139;,citation_journal_title=Computers in Human Behavior;,citation_publisher=Elsevier BV;">
<meta name="citation_reference" content="citation_title=The temporal dynamics of online problem-based learning: Why and when sequence matters;,citation_author=Mohammed Saqr;,citation_author=Sonsoles López-Pernas;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://doi.org/10.1007/s11412-023-09385-1;,citation_issue=1;,citation_doi=10.1007/s11412-023-09385-1;,citation_issn=1556-1615;,citation_volume=18;,citation_journal_title=International Journal of Computer-Supported Collaborative Learning;">
<meta name="citation_reference" content="citation_title=Efficient agglomerative hierarchical clustering;,citation_author=Athman Bouguettaya;,citation_author=Qi Yu;,citation_author=Xumin Liu;,citation_author=Xiangmin Zhou;,citation_author=Andy Song;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_issue=5;,citation_doi=https://doi.org/10.1016/j.eswa.2014.09.054;,citation_issn=0957-4174;,citation_volume=42;,citation_journal_title=Expert Systems with Applications;">
<meta name="citation_reference" content="citation_title=Efficient hierarchical clustering of large high dimensional datasets;,citation_author=Sean Gilpin;,citation_author=Buyue Qian;,citation_author=Ian Davidson;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_fulltext_html_url=https://doi.org/10.1145/2505515.2505527;,citation_doi=10.1145/2505515.2505527;,citation_isbn=9781450322638;,citation_conference_title=Proceedings of the 22nd ACM international conference on information &amp;amp;amp; knowledge management;,citation_conference=Association for Computing Machinery;,citation_series_title=CIKM ’13;">
<meta name="citation_reference" content="citation_title=Analytics of learning strategies: Role of course design and delivery modality;,citation_author=Wannisa Matcha;,citation_author=Dragan Gašević;,citation_author=Nora’ayu Ahmad Uzir;,citation_author=Jelena Jovanović;,citation_author=Abelardo Pardo;,citation_author=Lisa Lim;,citation_author=Jorge Maldonado-Mahauad;,citation_author=Sheridan Gentili;,citation_author=Mar Pérez-Sanagustı́n;,citation_author=Yi-Shan Tsai;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_issue=2;,citation_doi=10.18608/jla.2020.72.3;,citation_issn=1929-7750;,citation_volume=7;,citation_journal_title=Journal of Learning Analytics;,citation_publisher=SoLAR;">
<meta name="citation_reference" content="citation_title=Discovery and temporal analysis of MOOC study patterns;,citation_author=Mina Shirvani Boroujeni;,citation_author=Pierre Dillenbourg;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_issue=1;,citation_doi=10.18608/jla.2019.61.2;,citation_issn=1929-7750, 1929-7750;,citation_volume=6;,citation_journal_title=Journal of Learning Analytics;,citation_publisher=SoLAR;">
<meta name="citation_reference" content="citation_title=Unfolding students’ online assignment submission behavioral patterns using temporal learning analytics;,citation_author=Mehmet Kokoç;,citation_author=Gökhan Akçapınar;,citation_author=Mohammad Nehal Hasnine;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_fulltext_html_url=https://www.jstor.org/stable/26977869;,citation_issue=1;,citation_issn=1436-4522;,citation_volume=24;,citation_journal_title=Educational Technology &amp;amp;amp; Society;,citation_publisher=International Forum of Educational Technology &amp;amp; Society;">
<meta name="citation_reference" content="citation_title=A measurement model of gestures in an embodied learning environment: Accounting for temporal dependencies;,citation_author=Alejandro Andrade;,citation_author=Joshua A Danish;,citation_author=Adam V Maltese;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_fulltext_html_url=https://www.learning-analytics.info/index.php/JLA/article/view/5418;,citation_issue=3;,citation_doi=10.18608/jla.2017.43.3;,citation_issn=1929-7750, 1929-7750;,citation_volume=4;,citation_journal_title=Journal of Learning Analytics;,citation_publisher=SoLAR;">
<meta name="citation_reference" content="citation_title=Generating and comparing knowledge graphs of medical processes using pMineR;,citation_author=Roberto Gatta;,citation_author=Mauro Vallati;,citation_author=Jacopo Lenkowicz;,citation_author=Eric Rojas;,citation_author=Andrea Damiani;,citation_author=Lucia Sacchi;,citation_author=Berardino De Bari;,citation_author=Arianna Dagliati;,citation_author=Carlos Fernandez-Llatas;,citation_author=Matteo Montesi;,citation_author=Antonio Marchetti;,citation_author=Maurizio Castellano;,citation_author=Vincenzo Valentini;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_fulltext_html_url=http://dx.doi.org/10.1145/3148011.3154464;,citation_doi=10.1145/3148011.3154464;,citation_isbn=9781450355537;,citation_conference_title=Proceedings of the knowledge capture conference;,citation_conference=ACM;">
<meta name="citation_reference" content="citation_title=Predicting the stability of early employment with its timing and childhood social and health-related predictors: A mixture markov model approach;,citation_author=Satu Helske;,citation_author=Markus Keski-Säntti;,citation_author=Juha Kivelä;,citation_author=Aapo Juutinen;,citation_author=Antti Kääriälä;,citation_author=Mika Gissler;,citation_author=Marko Merikukka;,citation_author=Tea Lallukka;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_issue=1;,citation_volume=14;,citation_journal_title=Longitudinal and Life Course Studies;,citation_publisher=Bristol University Press;">
<meta name="citation_reference" content="citation_title=The why, the how, and the when of educational process mining in R;,citation_author=Sonsoles López-Pernas;,citation_author=Mohammed Saqr;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_inbook_title=Learning analytics methods and tutorials: A practical guide using R;">
<meta name="citation_reference" content="citation_title=Applying learning analytics to map students’ self-regulated learning tactics in an academic writing course;,citation_author=Ward Peeters;,citation_author=Mohammed Saqr;,citation_author=Olga Viberg;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_volume=1;,citation_conference_title=Proceedings of the 28th international conference on computers in education;,citation_conference=Asia-Pacific Society for Computers in Education;">
<meta name="citation_reference" content="citation_title=Transferring effective learning strategies across learning contexts matters: A study in problem-based learning;,citation_author=Mohammed Saqr;,citation_author=Wannisa Matcha;,citation_author=Jelena Jovanovic;,citation_author=Dragan Gašević;,citation_author=Sonsoles López-Pernas;,citation_author=others;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_journal_title=Australasian Journal of Educational Technology;">
</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">A Modern Approach to Transition Analysis and Process Mining with Markov Models in Education</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../../">Learning analytics methods and tutorials</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/lamethods/labook-code/" title="Source Code" class="sidebar-tool px-1"><i class="bi bi-github"></i></a>
</div>
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../index.html" class="sidebar-item-text sidebar-link">Welcome</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contributors.html" class="sidebar-item-text sidebar-link">Contributors</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch01-intro/intro.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">Getting started</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch02-data/ch2-data.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Data</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch03-intro-r/ch3-intor.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Intro to R</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch04-data-cleaning/ch4-datacleaning.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Data cleaning</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch05-basic-stats/ch5-stats.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Basic statistics</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch06-data-visualization/ch6-viz.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Data visualization</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">Machine Learning</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch07-prediction/ch7-pred.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Predictive modeling</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch08-clustering/ch8-clus.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Dissimilarity-based Clustering</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch09-model-based-clustering/ch9-model.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Model-based clustering</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">Temporal methods</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch10-sequence-analysis/ch10-seq.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Sequence analysis</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch11-vasstra/ch11-vasstra.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">VaSSTra</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch12-markov/ch12-markov.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Markov models</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch13-multichannel/ch13-multi.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Multi-channel sequences</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch14-process-mining/ch14-process.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Process mining</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">Network analysis</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch15-sna/ch15-sna.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Social Network Analysis</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch16-community/ch16-comm.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Community detection</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch17-temporal-networks/ch17-tna.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Temporal Networks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch18-ena-ona/ch18-ena.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Epistemic Network Analysis</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true">Psychometrics</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch19-psychological-networks/ch19-psych.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Psychological networks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch20-factor-analysis/ch20-factor.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Factor analysis</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch21-sem/ch21-sem.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Structured Equation Modeling</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch22-conclusion/ch22-conclusion.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Conclusion</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction"><span class="toc-section-number">1</span>  Introduction</a></li>
  <li><a href="#methodological-background" id="toc-methodological-background" class="nav-link" data-scroll-target="#methodological-background"><span class="toc-section-number">2</span>  Methodological Background</a>
  <ul class="collapse">
  <li><a href="#markov-model" id="toc-markov-model" class="nav-link" data-scroll-target="#markov-model"><span class="toc-section-number">2.1</span>  Markov model</a></li>
  <li><a href="#mixture-markov-model" id="toc-mixture-markov-model" class="nav-link" data-scroll-target="#mixture-markov-model"><span class="toc-section-number">2.2</span>  Mixture Markov model</a></li>
  <li><a href="#hidden-markov-model" id="toc-hidden-markov-model" class="nav-link" data-scroll-target="#hidden-markov-model"><span class="toc-section-number">2.3</span>  Hidden Markov model</a></li>
  <li><a href="#mixture-hidden-markov-models" id="toc-mixture-hidden-markov-models" class="nav-link" data-scroll-target="#mixture-hidden-markov-models"><span class="toc-section-number">2.4</span>  Mixture hidden Markov models</a></li>
  <li><a href="#multi-channel-sequences" id="toc-multi-channel-sequences" class="nav-link" data-scroll-target="#multi-channel-sequences"><span class="toc-section-number">2.5</span>  Multi-channel sequences</a></li>
  <li><a href="#estimating-model-parameters" id="toc-estimating-model-parameters" class="nav-link" data-scroll-target="#estimating-model-parameters"><span class="toc-section-number">2.6</span>  Estimating model parameters</a></li>
  </ul></li>
  <li><a href="#review-of-the-literature" id="toc-review-of-the-literature" class="nav-link" data-scroll-target="#review-of-the-literature"><span class="toc-section-number">3</span>  Review of the literature</a></li>
  <li><a href="#examples" id="toc-examples" class="nav-link" data-scroll-target="#examples"><span class="toc-section-number">4</span>  Examples</a>
  <ul class="collapse">
  <li><a href="#steps" id="toc-steps" class="nav-link" data-scroll-target="#steps"><span class="toc-section-number">4.1</span>  Steps of estimation</a></li>
  <li><a href="#markov" id="toc-markov" class="nav-link" data-scroll-target="#markov"><span class="toc-section-number">4.2</span>  Markov models</a></li>
  <li><a href="#process" id="toc-process" class="nav-link" data-scroll-target="#process"><span class="toc-section-number">4.3</span>  Stochastic process mining with Markovian models</a></li>
  </ul></li>
  <li><a href="#conclusions-further-readings" id="toc-conclusions-further-readings" class="nav-link" data-scroll-target="#conclusions-further-readings"><span class="toc-section-number">5</span>  Conclusions &amp; further readings</a></li>
  <li><a href="#acknowledgements" id="toc-acknowledgements" class="nav-link" data-scroll-target="#acknowledgements"><span class="toc-section-number">6</span>  Acknowledgements</a></li>
  <li><a href="#bibliography" id="toc-bibliography" class="nav-link" data-scroll-target="#bibliography">References</a></li>
  </ul>
</nav>
    <div class="quarto-margin-footer"><div class="margin-footer-item">
<p><small>© 2023 The authors</small></p>
</div></div></div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">A Modern Approach to Transition Analysis and Process Mining with Markov Models in Education</span></h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Authors</div>
    <div class="quarto-title-meta-contents">
             <p>Jouni Helske </p>
             <p>Satu Helske </p>
             <p>Mohammed Saqr </p>
             <p>Sonsoles López-Pernas </p>
             <p>Keefe Murphy </p>
          </div>
  </div>
    
  
    
  </div>
  
<div>
  <div class="abstract">
    <div class="abstract-title">Abstract</div>
    This chapter presents an introduction to Markovian modelling for the analysis of sequence data. Contrary to the deterministic approach seen in the previous sequence analysis chapters, Markovian models are probabilistic models, focusing on the transitions between states instead of studying sequences as a whole. The chapter provides an introduction to this method and differentiates between its most common variations: first-order Markov models, hidden Markov models, mixture Markov models, and mixture hidden Markov models. In addition to a thorough explanation and contextualisation within the existing literature, the chapter provides a step-by-step tutorial on how to implement each type of Markovian model using the R package <code>seqHMM</code>. The chapter also provides a complete guide to performing stochastic process mining with Markovian models as well as plotting, comparing and clustering different process models.
  </div>
</div>

</header>

<section id="introduction" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="introduction"><span class="header-section-number">1</span> Introduction</h2>
<p>In the previous two chapters, we have learned about sequence analysis <span class="citation" data-cites="Saqr2024-tv LopezPernas2024">[<a href="#ref-Saqr2024-tv" role="doc-biblioref">1</a>, <a href="#ref-LopezPernas2024" role="doc-biblioref">2</a>]</span> and its relevance to educational research. This chapter delves into a closely-related method: Markovian models. Specifically, we focus on a particular type of Markovian model, where the data are assumed to be categorical and observed at discrete time intervals, as per the previous chapters about sequence analysis, although in general Markovian models are not restricted to categorical data. One of the main differences between sequence analysis and Markovian modelling is that the former relies on deterministic data mining, whereas the latter uses probabilistic models <span class="citation" data-cites="Liao2022">[<a href="#ref-Liao2022" role="doc-biblioref">3</a>]</span>. Moreover, sequence analysis takes a more holistic approach by analysing sequences as a whole, whereas Markovian modelling focuses on the transitions between states, their probability, and the reasons (covariates) which explain why these transitions happen.</p>
<p>We provide an introduction and practical guide to the topic of Markovian models for the analysis of sequence data. While we try to avoid advanced mathematical notations, to allow the reader to continue to other, more advanced sources when necessary, we do introduce the basic mathematical concepts of Markovian models. When doing so, we use the same notation as in the R package <code>seqHMM</code> <span class="citation" data-cites="Helske2019">[<a href="#ref-Helske2019" role="doc-biblioref">4</a>]</span>, which we also use in the examples. In particular, we illustrate first-order Markov models, hidden Markov models, mixture Markov models, and mixture hidden Markov models with applications to synthetic data on students’ collaboration roles throughout a complete study program.</p>
<p>The chapter proceeds to describe the theoretical underpinnings on each method in turn, then showcases each method with code, before presenting some conclusions and further readings. In addition to the aforementioned applications to collaboration roles and achievement sequences, we also provide a demonstration of the utility of Markovian models in another context, namely process mining. In the process mining application, we leverage Markov models and mixture Markov models to explore learning management system logs. Finally, we conclude with a brief discussion of Markovian models in general and provide some recommendations for further reading of advanced topics in this area as a whole.</p>
</section>
<section id="methodological-background" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="methodological-background"><span class="header-section-number">2</span> Methodological Background</h2>
<section id="markov-model" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="markov-model"><span class="header-section-number">2.1</span> Markov model</h3>
<p>The simple first-order Markov chain or Markov model (MM) can be used to model transitions between successive states. In the first-order MM, given the current observation, the next observation in the sequence is independent of the past —this is called the <em>Markov property</em> (the order of MM determines on how many previous observations the next observation depends on). For example, when predicting a student’s school success in the fourth year under a first-order model, we only need to consider their success in the third year, while their success in the first and second year give no additional information for the prediction (see <a href="#fig-dag">Figure&nbsp;<span>12.1</span></a> for an illustration). As such, the model is said to be memoryless.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-dag" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="mm_dag.png" class="img-fluid figure-img" style="width:100.0%"></p>
<p></p><figcaption class="figure-caption"><strong>Figure</strong>&nbsp;1<strong>.</strong> Illustration of the Markov Model. The nodes <span class="math inline">\(Y_1\)</span> to <span class="math inline">\(Y_4\)</span> refer to states at time points 1 to 4. The arrows indicate dependencies between states.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>As an example, consider the data described in <a href="#tbl-sequences">Table&nbsp;<span>12.1</span></a> which includes four sequences of length ten. The <em>alphabet</em> — that is, the list of all possible states appearing in the data — consists of two types of observed state; low achievement success (<span class="math inline">\(L\)</span>) and high achievement (<span class="math inline">\(H\)</span>). Here, the individuals are assumed to be independent from one another:</p>
<div id="tbl-sequences" class="anchored">
<table class="table">
<caption>Table&nbsp;1<strong>.</strong> Four example sequences of school achievement with individuals A–D across the rows and years 1–10 across the columns.</caption>
<thead>
<tr class="header">
<th></th>
<th>1</th>
<th>2</th>
<th>3</th>
<th>4</th>
<th>5</th>
<th>6</th>
<th>7</th>
<th>8</th>
<th>9</th>
<th>10</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>A</td>
<td>L</td>
<td>L</td>
<td>L</td>
<td>H</td>
<td>L</td>
<td>H</td>
<td>L</td>
<td>H</td>
<td>H</td>
<td>H</td>
</tr>
<tr class="even">
<td>B</td>
<td>L</td>
<td>H</td>
<td>H</td>
<td>L</td>
<td>H</td>
<td>L</td>
<td>H</td>
<td>L</td>
<td>L</td>
<td>H</td>
</tr>
<tr class="odd">
<td>C</td>
<td>H</td>
<td>H</td>
<td>L</td>
<td>H</td>
<td>L</td>
<td>L</td>
<td>H</td>
<td>L</td>
<td>H</td>
<td>H</td>
</tr>
<tr class="even">
<td>D</td>
<td>H</td>
<td>H</td>
<td>L</td>
<td>L</td>
<td>L</td>
<td>H</td>
<td>L</td>
<td>L</td>
<td>L</td>
<td>H</td>
</tr>
</tbody>
</table>
</div>
<p>Say <span class="math inline">\(t\)</span> describes the position in the sequence, or in this example, the year (in other words, here <span class="math inline">\(t\)</span> runs from 1 to 10). If we assume that the probability of observing <span class="math inline">\(L\)</span> or <span class="math inline">\(H\)</span> at any given point <span class="math inline">\(t\)</span> depends on the current observation only, we can estimate the <em>transition probabilities</em> <span class="math inline">\(a_{LL}\)</span> (from state <span class="math inline">\(L\)</span> to state <span class="math inline">\(L\)</span>), <span class="math inline">\(a_{LH}\)</span> (<span class="math inline">\(L\)</span> to <span class="math inline">\(H\)</span>), <span class="math inline">\(a_{HL}\)</span> (<span class="math inline">\(H\)</span> to <span class="math inline">\(L\)</span>), and <span class="math inline">\(a_{HH}\)</span> (<span class="math inline">\(H\)</span> to <span class="math inline">\(H\)</span>) by calculating the number of observed transitions from each state to all states and scaling these with the total number of transitions from that state. Mathematically, we can write the transition probability <span class="math inline">\(a_{rs}\)</span> from state <span class="math inline">\(r\)</span> to state <span class="math inline">\(s\)</span> as</p>
<p><span class="math display">\[a_{rs}=P(z_t = s\,|\,z_{t-1} = r), \ s,r \in \{L,H\},\]</span></p>
<p>which simply states that the observed state <span class="math inline">\(z_t\)</span> in year <span class="math inline">\(t\)</span> being <span class="math inline">\(L\)</span> or <span class="math inline">\(H\)</span> depends on which of the two states were observed in the previous year <span class="math inline">\(t-1\)</span>. For example, to compute <span class="math inline">\(a_{LH}=P(z_t=H\,|\,z_{t-1}=L)\)</span>, the probability of transitioning from the origin state <span class="math inline">\(L\)</span> to the destination state <span class="math inline">\(H\)</span>, we divide the eight observed transitions to state <span class="math inline">\(H\)</span> from state <span class="math inline">\(L\)</span> by 20, which is the total number of transitions from <span class="math inline">\(L\)</span> to any state.</p>
<p>The basic MM assumes that the transition probabilities remain constant in time (this property is called <em>time-homogeneity</em>). This means, for example, that the probabilities of transitioning from the low-achievement state to the high-achievement state is the same in the ninth year as it was in the second year. We can collect the transition probabilities in a transition matrix (which we call <span class="math inline">\(A\)</span>) which shows all of the possible transition probabilities between each pair of origin and destination states, as illustrated in <a href="#tbl-transmat">Table&nbsp;<span>12.2</span></a>. For example, when a student has low achievement in year <span class="math inline">\(t\)</span>, they have a 40 percent probability to have low achievement in year <span class="math inline">\(t+1\)</span> and a higher 60 percent probability to transition to high achievement instead, regardless of the year <span class="math inline">\(t\)</span>. Notice that the probabilities in each row must add up to 1 (or 100%).</p>
<div id="tbl-transmat" class="anchored">
<table class="table">
<caption>Table&nbsp;2<strong>.</strong> Transition matrix showing the probabilities of transitioning from one state to another (low or high achievement). The rows and columns describe the origin state and the destination state, respectively.</caption>
<thead>
<tr class="header">
<th></th>
<th><span class="math inline">\(\to\)</span> Low</th>
<th><span class="math inline">\(\to\)</span> High</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Low <span class="math inline">\(\to\)</span></td>
<td>8/20 = 0.4</td>
<td>12/20 = 0.6</td>
</tr>
<tr class="even">
<td>High <span class="math inline">\(\to\)</span></td>
<td>10/16 = 0.625</td>
<td>6/16 = 0.375</td>
</tr>
</tbody>
</table>
</div>
<p>Lastly, we need to define probabilities for the starting states of the sequences, i.e., the <em>initial probabilities</em> <span class="math display">\[\pi_s=P(z_1 = s), \ s \in \{L,H\}.\]</span></p>
<p>In the example, half of the students have low achievement and the other half have high achievement in the first year, so <span class="math inline">\(\pi_L=\pi_H = 0.5\)</span>. This basic MM is very simple and is often not realistic in the context of educational sciences. We can, however, extend the basic MM in several ways.</p>
<p>First of all, we can include covariates to explain the transition and/or initial probabilities. For example, if we think that transitioning from low to high achievement becomes more challenging as the students get older we may add time as an explanatory variable to the model, allowing the probability of transitioning from low to high achievement to decrease in time. We could also increase the order of the Markov chain, accounting for longer histories. This may be more realistic, but at the same time increasing the order makes the model considerably more complex, the more so the longer the history considered.</p>
<p>Secondly, one of the most useful extensions is the inclusion of hidden (or latent) states that cannot be observed directly but can be estimated from the sequence of observed states. An MM with time-constant hidden states is typically called the mixture Markov model (MMM). It can be used to find latent subpopulations, or in other words, to cluster sequence data. A model with time-varying hidden states is called the hidden Markov model (HMM), which allows the individuals to transition between the hidden states. Allowing for both time-constant and time-varying hidden states leads to a mixture hidden Markov model (MHMM). Unless otherwise specified, from now on when talking about hidden states we refer always to time-varying hidden states, while time-constant hidden states are referred to as clusters.</p>
</section>
<section id="mixture-markov-model" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="mixture-markov-model"><span class="header-section-number">2.2</span> Mixture Markov model</h3>
<p>Consider a common case in sequence analysis where individual sequences are assumed to be clustered into subpopulations such as those with typically high and low achievement. In the introductory sequence analysis chapter, the clustering of sequences was performed based on a matrix of pairwise dissimilarities between sequences. Alternatively, we can use the MMM to group the sequences based on their initial and transition probabilities, for example, into those who tend to stay in and transition to high achievement states and those that tend to stay in and transition to low achievement states, as illustrated in <a href="#tbl-transmatMMM">Table&nbsp;<span>12.3</span></a>.</p>
<div id="tbl-transmatMMM" class="tbl-parent quarto-layout-panel anchored">
<div class="panel-caption table-caption">
<p>Table&nbsp;3<strong>.</strong> Two transition matrices showing the probabilities of transitioning from one state of achievement to another in two clusters of Low achievement and High achievement. The rows and columns describe the origin state and the destination state, respectively.</p>
</div>
<div class="quarto-layout-row quarto-layout-valign-top">
<div id="tbl-trans-first" class="quarto-layout-cell quarto-layout-cell-subref anchored" data-ref-parent="tbl-transmatMMM" style="flex-basis: 50.0%;justify-content: center;">
<table class="table">
<caption>(a) Low achievement</caption>
<thead>
<tr class="header">
<th style="text-align: left;">Cluster: Low achievement</th>
<th style="text-align: left;"><span class="math inline">\(\to\)</span> Low</th>
<th style="text-align: left;"><span class="math inline">\(\to\)</span> High</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Low <span class="math inline">\(\to\)</span></td>
<td style="text-align: left;">0.8</td>
<td style="text-align: left;">0.2</td>
</tr>
<tr class="even">
<td style="text-align: left;">High <span class="math inline">\(\to\)</span></td>
<td style="text-align: left;">0.4</td>
<td style="text-align: left;">0.6</td>
</tr>
</tbody>
</table>
</div>
<div id="tbl-trans-second" class="quarto-layout-cell quarto-layout-cell-subref anchored" data-ref-parent="tbl-transmatMMM" style="flex-basis: 50.0%;justify-content: center;">
<table class="table">
<caption>(b) High achievement</caption>
<thead>
<tr class="header">
<th style="text-align: left;">Cluster: High achievement</th>
<th style="text-align: left;"><span class="math inline">\(\to\)</span> Low</th>
<th style="text-align: left;"><span class="math inline">\(\to\)</span> High</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Low <span class="math inline">\(\to\)</span></td>
<td style="text-align: left;">0.6</td>
<td style="text-align: left;">0.4</td>
</tr>
<tr class="even">
<td style="text-align: left;">High <span class="math inline">\(\to\)</span></td>
<td style="text-align: left;">0.1</td>
<td style="text-align: left;">0.9</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<p>In MMMs, we have a separate transition matrix <span class="math inline">\(A^k\)</span> for each cluster <span class="math inline">\(k\)</span> (for <span class="math inline">\(k=1,\ldots,K\)</span> clusters/subpopulations), and the initial state distribution defines the probabilities to start (and stay) in the hidden states corresponding to a particular cluster. This probabilistic clustering provides group membership probabilities for each sequence; these define how likely it is that each individual is a member of each cluster. We can easily add (time-constant) covariates to the model to explain the probabilities of belonging to each cluster. By incorporating covariates in this way we could, for example, find that being in a high-achievement cluster is predicted by gender or family background. However, we note that this is distinct from the aforementioned potential inclusion of covariates to explain the transition and/or initial probabilities.</p>
<p>An advantage of this kind of probabilistic modelling approach is that we can use traditional model selection methods such as likelihood information criteria or cross-validation for choosing the best model. For example, if the number of subpopulations is not known in advance —as is typically the case— we can compare models with different clustering solutions (e.g., those obtained with different numbers of clusters, different subsets of covariates, or different sets of initial probabilities, for example) and choose the best-fitting model with, for example, the Bayesian information criterion (BIC) <span class="citation" data-cites="schwarz1978">[<a href="#ref-schwarz1978" role="doc-biblioref">5</a>]</span>.</p>
</section>
<section id="hidden-markov-model" class="level3" data-number="2.3">
<h3 data-number="2.3" class="anchored" data-anchor-id="hidden-markov-model"><span class="header-section-number">2.3</span> Hidden Markov model</h3>
<p>The HMM can be useful in a number of cases when the state of interest cannot be directly measured or when there is measurement error in the observations. In HMMs, the Markov chain operates at the level of hidden states, which subsequently generate or emit observed states with different probabilities. For example, think about a progression of a student’s ability as a hidden state and school success as the observed state. We cannot measure true ability directly, but we can estimate the student’s progress by their test scores that are emissions of their ability. There is, however, some uncertainty in how well the test scores represent students’ true ability. For example, observing low test scores at some point in time does not necessarily mean the student has low ability; they might have scored lower than expected in the test due to other reasons such as being sick at that particular time. Such uncertainty can be reflected in the emission probabilities; for example, in the high-ability state students get high test scores eight times out of ten and low test scores with a 20 percent probability, while in the low-ability state the students get low test scores nine times out of ten and high test scores with a 10 percent probability. These probabilities are collected in an emission matrix as illustrated in <a href="#tbl-emissmatHMM">Table&nbsp;<span>12.4</span></a>.</p>
<div id="tbl-emissmatHMM" class="anchored">
<table class="table">
<caption>Table&nbsp;4<strong>.</strong> Emission matrix showing the probabilities of each hidden state (low or high ability) emitting each observed state (low or high test scores).</caption>
<thead>
<tr class="header">
<th></th>
<th>Low scores</th>
<th>High scores</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Low ability</td>
<td>0.9</td>
<td>0.1</td>
</tr>
<tr class="even">
<td>High ability</td>
<td>0.2</td>
<td>0.8</td>
</tr>
</tbody>
</table>
</div>
<p>Again, the full HMM is defined by a set of parameters: the initial state probabilities <span class="math inline">\(\pi_s\)</span>, the hidden state transition probabilities <span class="math inline">\(a_{rs}\)</span>, and the emission probabilities of observed states <span class="math inline">\(b_s(m)\)</span>. What is different to the MM is that in the HMM, the initial state probabilities <span class="math inline">\(\pi_s\)</span> define the probabilities of starting from each <em>hidden</em> state. Similarly, the transition probabilities <span class="math inline">\(a_{rs}\)</span> define the probabilities of transitioning from one <em>hidden</em> state to another hidden state. The emission probabilities <span class="math inline">\(b_s(m)\)</span> (collected in an emission matrix <span class="math inline">\(B\)</span>) define the probability of observing a particular state <span class="math inline">\(m\)</span> (e.g., low or high test scores) given the current hidden state <span class="math inline">\(s\)</span> (e.g., low or high ability).</p>
<p>When being in a certain hidden state, observed states occur randomly, following the emission probabilities. Mathematically speaking, instead of assuming the Markov property directly on our observations, we assume that the observations are conditionally independent given the underlying hidden state. We can visualise the HMM as a directed acyclic graph (DAG) illustrated in <a href="#fig-hmm">Figure&nbsp;<span>12.2</span></a>. Here <span class="math inline">\(Z\)</span> are the unobserved states (such as ability) which affect the distribution of the observed states <span class="math inline">\(Y\)</span> (test scores). At each time point <span class="math inline">\(t\)</span>, the state <span class="math inline">\(z_t\)</span> can obtain one of <span class="math inline">\(S\)</span> possible values (there are two hidden states in the example of low and high ability, so <span class="math inline">\(S=2\)</span>), which in turn defines how <span class="math inline">\(Y_t\)</span> is distributed.</p>
<div id="fig-hmm" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="hmm_dag.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption"><strong>Figure</strong>&nbsp;2<strong>.</strong> Illustration of the HMM. The nodes <span class="math inline">\(Z_1\)</span> to <span class="math inline">\(Z_4\)</span> refer to hidden states at time points 1 to 4, while the nodes <span class="math inline">\(Y_1\)</span> to <span class="math inline">\(Y_4\)</span> refer to observed states. The arrows indicate dependencies between hidden and/or observed states.</figcaption><p></p>
</figure>
</div>
</section>
<section id="mixture-hidden-markov-models" class="level3" data-number="2.4">
<h3 data-number="2.4" class="anchored" data-anchor-id="mixture-hidden-markov-models"><span class="header-section-number">2.4</span> Mixture hidden Markov models</h3>
<p>Combining the ideas of both time-constant clusters and time-varying hidden states leads to the concept of mixture hidden Markov model (MHMM). Here we assume that the population of interest consists of a finite number of subpopulations, each with their own HMM with varying transition and emission probabilities. For example, we could expect to find underlying groups which behave differently when estimating the progression of ability through the sequence of test scores, such as those that consistently stay on a low-ability or high-ability track (stayers) and those that move between low and high ability (movers). In this case, we need two transition matrices: the stayers’ transition matrix allows for no transitions while the movers’ transition matrix allows for transitioning between low and high ability, as illustrated in <a href="#tbl-transmatMHMM">Table&nbsp;<span>12.5</span></a>.</p>
<div id="tbl-transmatMHMM" class="tbl-parent quarto-layout-panel anchored">
<div class="panel-caption table-caption">
<p>Table&nbsp;5<strong>.</strong> Two transition matrices showing the probabilities of transitioning from one state of ability to another in two clusters, the Stayers and the Movers. The rows and columns describe the origin state and the destination state, respectively.</p>
</div>
<div class="quarto-layout-row quarto-layout-valign-top">
<div id="tbl-transmatMHMM-stayers" class="quarto-layout-cell quarto-layout-cell-subref anchored" data-ref-parent="tbl-transmatMHMM" style="flex-basis: 50.0%;justify-content: center;">
<table class="table">
<caption>(a) Stayers</caption>
<thead>
<tr class="header">
<th style="text-align: left;">Cluster: Stayers</th>
<th style="text-align: left;"><span class="math inline">\(\to\)</span> Low</th>
<th style="text-align: left;"><span class="math inline">\(\to\)</span> High</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Low <span class="math inline">\(\to\)</span></td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">High <span class="math inline">\(\to\)</span></td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">1</td>
</tr>
</tbody>
</table>
</div>
<div id="tbl-transmatMHMM-movers" class="quarto-layout-cell quarto-layout-cell-subref anchored" data-ref-parent="tbl-transmatMHMM" style="flex-basis: 50.0%;justify-content: center;">
<table class="table">
<caption>(b) Movers</caption>
<thead>
<tr class="header">
<th style="text-align: left;">Cluster: Movers</th>
<th style="text-align: left;"><span class="math inline">\(\to\)</span> Low</th>
<th style="text-align: left;"><span class="math inline">\(\to\)</span> High</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Low <span class="math inline">\(\to\)</span></td>
<td style="text-align: left;">0.6</td>
<td style="text-align: left;">0.4</td>
</tr>
<tr class="even">
<td style="text-align: left;">High <span class="math inline">\(\to\)</span></td>
<td style="text-align: left;">0.3</td>
<td style="text-align: left;">0.7</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<p>Similarly, we need two emission matrices that describe how the observed states are related to hidden states, as illustrated in <a href="#tbl-emissmatMHMM">Table&nbsp;<span>12.6</span></a>. In this example, there is a closer match between low/high ability and low/high test scores in the Stayers cluster in comparison to the Movers cluster.</p>
<div id="tbl-emissmatMHMM" class="tbl-parent quarto-layout-panel anchored">
<div class="panel-caption table-caption">
<p>Table&nbsp;6<strong>.</strong> Two emission matrices showing the probabilities of each hidden state (low or high ability) emitting each observed state (low or high test scores).</p>
</div>
<div class="quarto-layout-row quarto-layout-valign-top">
<div id="tbl-emissmatMHMM-stayers" class="quarto-layout-cell quarto-layout-cell-subref anchored" data-ref-parent="tbl-emissmatMHMM" style="flex-basis: 50.0%;justify-content: center;">
<table class="table">
<caption>(a) Stayers</caption>
<thead>
<tr class="header">
<th style="text-align: left;">Cluster: Stayers</th>
<th style="text-align: left;">Low scores</th>
<th style="text-align: left;">High scores</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Low ability</td>
<td style="text-align: left;">0.9</td>
<td style="text-align: left;">0.1</td>
</tr>
<tr class="even">
<td style="text-align: left;">High ability</td>
<td style="text-align: left;">0.1</td>
<td style="text-align: left;">0.9</td>
</tr>
</tbody>
</table>
</div>
<div id="tbl-emissmatMHMM-movers" class="quarto-layout-cell quarto-layout-cell-subref anchored" data-ref-parent="tbl-emissmatMHMM" style="flex-basis: 50.0%;justify-content: center;">
<table class="table">
<caption>(b) Movers</caption>
<thead>
<tr class="header">
<th style="text-align: left;">Cluster: Movers</th>
<th style="text-align: left;">Low scores</th>
<th style="text-align: left;">High scores</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Low ability</td>
<td style="text-align: left;">0.7</td>
<td style="text-align: left;">0.3</td>
</tr>
<tr class="even">
<td style="text-align: left;">High ability</td>
<td style="text-align: left;">0.2</td>
<td style="text-align: left;">0.8</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<p>Mathematically, when estimating a MHMM we first fix the number of clusters <span class="math inline">\(K\)</span>, and create a joint HMM consisting of <span class="math inline">\(K\)</span> submodels (HMMs). The number of hidden states does not have to be fixed but can vary by submodel, so that the HMMs have more hidden states for some clusters and fewer for others (in our example, because the transition matrix is of the Stayers cluster is diagonal, we could also split the cluster into two single state clusters, one corresponding to low and other to high ability). This can increase the burden of model selection, so often a common number of hidden states is assumed for each cluster for simplicity. In any case, the initial state probabilities of this joint model define how sequences are assigned to different clusters. We estimate this joint model using the whole data and calculate cluster membership probabilities for each individual. The idea of using mixtures of HMMs has appeared in literature under various names with slight variations, e.g., <span class="citation" data-cites="vandePol1990">[<a href="#ref-vandePol1990" role="doc-biblioref">6</a>]</span>, <span class="citation" data-cites="Vermunt">[<a href="#ref-Vermunt" role="doc-biblioref">7</a>]</span>, and <span class="citation" data-cites="Helske2019">[<a href="#ref-Helske2019" role="doc-biblioref">4</a>]</span>. Notably, MHMMs inherit from MMMs the ability to incorporate covariates to predict cluster memberships.</p>
</section>
<section id="multi-channel-sequences" class="level3" data-number="2.5">
<h3 data-number="2.5" class="anchored" data-anchor-id="multi-channel-sequences"><span class="header-section-number">2.5</span> Multi-channel sequences</h3>
<p>There are two options to analyse multi-channel (or multi-domain or multi-dimensional) sequence data with Markovian models. The first option is to combine observed states in different channels into one set of single-channel sequences with an expanded alphabet. This option is simple, and works for MMs, HMMs, MMMs, and MHMMs, but can easily lead to complex models as the number of states and channels increases considerably. The second option, which can only be used when working with HMMs and MHMMs, is to treat the observed states in each channel independently given the current hidden state. This can be easily performed by defining multiple emission probability matrices, one for each channel. The assumption of conditional independence simplifies the model, but is sometimes unrealistic, in which case it is better to resort to the first option and convert the data into single-channel sequences. Both options are discussed further in Chapter 13 <span class="citation" data-cites="Lopez-Pernas2024-kf">[<a href="#ref-Lopez-Pernas2024-kf" role="doc-biblioref">8</a>]</span>, a dedicated chapter on multi-channel sequences, where applications of distance-based and Markovian clustering approaches are presented. In this chapter, we henceforth focus on single-channel sequences.</p>
</section>
<section id="estimating-model-parameters" class="level3" data-number="2.6">
<h3 data-number="2.6" class="anchored" data-anchor-id="estimating-model-parameters"><span class="header-section-number">2.6</span> Estimating model parameters</h3>
<p>The model parameters, i.e.&nbsp;the elements of the initial probability vectors <span class="math inline">\(\pi\)</span>, transition probability matrices <span class="math inline">\(A\)</span>, and emission probability matrices <span class="math inline">\(B\)</span>, can be estimated from data using various methods. Typical choices are the Baum-Welch algorithm (an instance of the expectation-maximisation, i.e., the EM algorithm) and direct (numerical) maximum likelihood estimation. It is possible to restrict models, for example, by setting some parameters to fixed values (typically zeros), for example, to make certain starting states, transitions, or emissions impossible.</p>
<p>After the parameter estimation, in addition to studying the estimated model parameters upon convergence, we can, for example, compute cluster-membership probabilities for each individual and find the most probable paths of hidden state sequences using the Viterbi algorithm (<span class="citation" data-cites="Rabiner1989">[<a href="#ref-Rabiner1989" role="doc-biblioref">9</a>]</span>). These can be further analysed and visualised for interpretation.</p>
</section>
</section>
<section id="review-of-the-literature" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="review-of-the-literature"><span class="header-section-number">3</span> Review of the literature</h2>
<p>Markovian methods have been used across several domains in education and have gained renewed interest with the surge in learning analytics and educational data mining. Furthermore, the introduction of specialised R packages (e.g., <code>seqHMM</code> <span class="citation" data-cites="Helske2018">[<a href="#ref-Helske2018" role="doc-biblioref">10</a>]</span>) and software applications (e.g., Mplus <span class="citation" data-cites="mplus Muthen">[<a href="#ref-mplus" role="doc-biblioref">11</a>, <a href="#ref-Muthen" role="doc-biblioref">12</a>]</span>) have made it easier to implement Markov models. One of the most common applications of Markovian methods is the clustering of sequence data <span class="citation" data-cites="Tormanen2022-ux Tormanen2023-gz Fincham2019-yz">[<a href="#ref-Tormanen2022-ux" role="doc-biblioref">13</a>–<a href="#ref-Fincham2019-yz" role="doc-biblioref">15</a>]</span>. Markov models offer a credible alternative to existing distance-based methods (e.g.&nbsp;optimal matching) and can be used with different sequence types (e.g.&nbsp;multi-channel sequences). Furthermore, Markovian methods offer some advantages in clustering sequential data such as the inclusion of covariates that can explain why a sequence emerged (e.g., <span class="citation" data-cites="Roles">[<a href="#ref-Roles" role="doc-biblioref">16</a>]</span>). More importantly, Markovian models are relatively scalable and can be used to cluster large sequences <span class="citation" data-cites="IHE">[<a href="#ref-IHE" role="doc-biblioref">17</a>]</span>. As Saqr et al. <span class="citation" data-cites="IHE">[<a href="#ref-IHE" role="doc-biblioref">17</a>]</span> noted, large sequences are hard to cluster using standard methods such as hierarchical clustering, which is memory inefficient, and hard to parallelise or scale <span class="citation" data-cites="BOUGUETTAYA20152785 Gilpin13">[<a href="#ref-BOUGUETTAYA20152785" role="doc-biblioref">18</a>, <a href="#ref-Gilpin13" role="doc-biblioref">19</a>]</span>. Furthermore, distance-based clustering methods are limited by the theoretical maximum dimension of a matrix in R which is 2,147,483,647 (i.e., a maximum of 46,430 sequences). In such a case, Markovian methods may be the solution.</p>
<p>Examples of Markovian methods in clustering sequences are plentiful. For example, HMMs have been used to cluster students’ sequences of learning management system (LMS) trace data to detect their patterns of activities or what the authors referred to as learning tactics and strategies <span class="citation" data-cites="Fincham2019-yz">[<a href="#ref-Fincham2019-yz" role="doc-biblioref">15</a>]</span>. Another close example was that of López-Pernas and Saqr <span class="citation" data-cites="Bringing">[<a href="#ref-Bringing" role="doc-biblioref">20</a>]</span>, who used HMMs to cluster multi-channel data of students’ learning strategies of two different tools (an LMS and an automated assessment tool). Other examples include using HMM in clustering sequences of students’ engagement states <span class="citation" data-cites="Engagement">[<a href="#ref-Engagement" role="doc-biblioref">21</a>]</span>, sequences of students’ collaborative roles <span class="citation" data-cites="Roles">[<a href="#ref-Roles" role="doc-biblioref">16</a>]</span>, or sequences of self-regulation <span class="citation" data-cites="Tormanen2022-ux Tormanen2023-gz">[<a href="#ref-Tormanen2022-ux" role="doc-biblioref">13</a>, <a href="#ref-Tormanen2023-gz" role="doc-biblioref">14</a>]</span>.</p>
<p>Markovian methods are also popular in studying transitions and have therefore been used across several applications and with different types of data. One of the most common usages is what is known as stochastic processes mining which typically uses first-order Markov models to map students’ transitions between learning activities. For example, Matcha et al. <span class="citation" data-cites="Matcha2020-jp">[<a href="#ref-Matcha2020-jp" role="doc-biblioref">22</a>]</span> used first-order Markov models to study students’ processes of transitions between different learning tactics. Other uses include studying the transitions between tactics of academic writing <span class="citation" data-cites="Peeters2020-wa">[<a href="#ref-Peeters2020-wa" role="doc-biblioref">23</a>]</span>, between self-regulated learning events <span class="citation" data-cites="Lim2023-kg">[<a href="#ref-Lim2023-kg" role="doc-biblioref">24</a>]</span>, or within collaborative learning settings <span class="citation" data-cites="Saqr2023-he">[<a href="#ref-Saqr2023-he" role="doc-biblioref">25</a>]</span>. Yet, most of such work has been performed by the <code>pMiner</code> R package <span class="citation" data-cites="Gatta2017-rg">[<a href="#ref-Gatta2017-rg" role="doc-biblioref">26</a>]</span>, which was recently removed from The Comprehensive R Archive Network (CRAN) due to slow updates and incompatibility with existing guidelines. This chapter offers a modern alternative that uses modern and flexible methods for fitting, plotting, and clustering stochastic process mining models as well as the possibility to add covariates to understand “why” different transitions pattern emerged.</p>
<p>Indeed, transition analysis in general has been a popular usage for Markovian models and has been used across several studies. For instance, for the analysis of temporal patterns of students’ activities in online learning (e.g., <span class="citation" data-cites="Boroujeni2019-vf">[<a href="#ref-Boroujeni2019-vf" role="doc-biblioref">27</a>]</span>), or transitions between latent states <span class="citation" data-cites="Andrade2017-we">[<a href="#ref-Andrade2017-we" role="doc-biblioref">28</a>]</span>, or transitions between assignment submission patterns <span class="citation" data-cites="Kokoc2021-rc">[<a href="#ref-Kokoc2021-rc" role="doc-biblioref">29</a>]</span>.</p>
</section>
<section id="examples" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="examples"><span class="header-section-number">4</span> Examples</h2>
<p>As a first step, we will import all the packages required for our analyses. We have used most of them throughout the book. Below is a brief summary:</p>
<ul>
<li><code>qgraph</code>: A package for visualising networks, which can be used to plot transition probabilities <span class="citation" data-cites="qgraph">[<a href="#ref-qgraph" role="doc-biblioref">30</a>]</span>. This is used only for the process mining application in Section <span class="math inline">\(\ref{process}\)</span>.</li>
<li><code>rio</code>: A package for reading and saving data files with different extensions <span class="citation" data-cites="rio">[<a href="#ref-rio" role="doc-biblioref">31</a>]</span>.</li>
<li><code>seqHMM</code>: A package designed for fitting hidden (latent) Markov models and mixture hidden Markov models for social sequence data and other categorical time series <span class="citation" data-cites="seqHMM">[<a href="#ref-seqHMM" role="doc-biblioref">32</a>]</span>.</li>
<li><code>tidyverse</code>: A package that encompasses several basic packages for data manipulation and wrangling <span class="citation" data-cites="tidyverse">[<a href="#ref-tidyverse" role="doc-biblioref">33</a>]</span>.</li>
<li><code>TraMineR</code>: As seen in the introductory sequence analysis chapter, this package helps us construct, analyze, and visualise sequences from time-ordered states or events <span class="citation" data-cites="Gabadinho2011">[<a href="#ref-Gabadinho2011" role="doc-biblioref">34</a>]</span>.</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(qgraph)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rio)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(seqHMM)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(TraMineR)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Henceforth, we divide our examples into two parts: the first largely focuses on traditional uses of the <code>seqHMM</code> package to fit Markovian models of varying complexity to sequence data; the latter presents a demonstration of Markovian models from the perspective of process mining. We outline the steps involved in using <code>seqHMM</code> in general in Section <span class="math inline">\(\ref{steps}\)</span>, demonstrate the application of MMs, HMMs, MMMs, and MHMMs in Section <span class="math inline">\(\ref{markov}\)</span>, and explore process mining using Markovian models in Section <span class="math inline">\(\ref{process}\)</span>, leveraging much of the steps and code from the previous two sections. We note that different datasets are used in Section <span class="math inline">\(\ref{markov}\)</span> and Section <span class="math inline">\(\ref{process}\)</span>; we begin by importing the data required for Section <span class="math inline">\(\ref{markov}\)</span> and defer the importing of the data used in the process mining application to the later section.</p>
<p>With this in mind, we start by using the <code>ìmport()</code> function from the <code>rio</code> package to import our sequence data. Based on the description of the MHMM in <span class="citation" data-cites="Satu">[<a href="#ref-Satu" role="doc-biblioref">35</a>]</span>, we used the <code>seqHMM</code> package to simulate a synthetic dataset (<code>simulated_data</code>) consisting of students’ collaboration roles (obtained from <span class="citation" data-cites="SAQR2022104581">[<a href="#ref-SAQR2022104581" role="doc-biblioref">36</a>]</span>) on different courses across a whole program. As the original data, the simulation was based on the two-channel model (collaboration and achievement), but we only use the collaboration sequences in the following examples, and leave the multi-channel sequence analysis to Chapter 13 <span class="citation" data-cites="Lopez-Pernas2024-kf">[<a href="#ref-Lopez-Pernas2024-kf" role="doc-biblioref">8</a>]</span>. While not available in the original study, we also simulated students’ high school grade point average (<code>GPA</code>, for simplicity categorised into three levels) for each student, which will be used to predict cluster memberships. Using this data, we show how the <code>seqHMM</code> package can be used to analyse such sequences. We start with the simple MM, and then transition to HMMs and their mixtures. To be able to use the <code>seqHMM</code> functions, we need to convert the imported data to a sequence using the function <code>seqdef()</code> from the <code>TraMineR</code> package (see Chapter 10 <span class="citation" data-cites="Saqr2024-tv">[<a href="#ref-Saqr2024-tv" role="doc-biblioref">1</a>]</span> for more information about creating <code>stslist</code> objects). We subsequently assign a colour palette to each state in the alphabet for later visualisations using the function <code>cpal()</code>. Finally, we can also extract the covariate information separately (<code>cov_data</code>).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>URL <span class="ot">&lt;-</span> <span class="st">"https://github.com/sonsoleslp/labook-data/raw/main/"</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>simulated_data <span class="ot">&lt;-</span> <span class="fu">import</span>(<span class="fu">paste0</span>(URL, <span class="st">"12_longitudinalRoles/simulated_roles.csv"</span>))</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>roles_seq <span class="ot">&lt;-</span> <span class="fu">seqdef</span>(</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>  simulated_data, </span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">var =</span> <span class="dv">3</span><span class="sc">:</span><span class="dv">22</span>, </span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">alphabet =</span> <span class="fu">c</span>(<span class="st">"Isolate"</span>, <span class="st">"Mediator"</span>, <span class="st">"Leader"</span>),</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">cnames =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">20</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code> [&gt;] 3 distinct states appear in the data: </code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>     1 = Isolate</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>     2 = Leader</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>     3 = Mediator</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code> [&gt;] state coding:</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>       [alphabet]  [label]  [long label] </code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>     1  Isolate     Isolate  Isolate</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>     2  Mediator    Mediator Mediator</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>     3  Leader      Leader   Leader</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code> [&gt;] 200 sequences in the data set</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code> [&gt;] min/max sequence length: 20/20</code></pre>
</div>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cpal</span>(roles_seq) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"#FBCE4B"</span>, <span class="st">"#F67067"</span>, <span class="st">"#5C2262"</span>)</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>cov_data <span class="ot">&lt;-</span> simulated_data <span class="sc">|&gt;</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(ID, GPA) <span class="sc">|&gt;</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">GPA =</span> <span class="fu">factor</span>(GPA, <span class="at">levels =</span> <span class="fu">c</span>(<span class="st">"Low"</span>, <span class="st">"Middle"</span>, <span class="st">"High"</span>)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="steps" class="level3" data-number="4.1">
<h3 data-number="4.1" class="anchored" data-anchor-id="steps"><span class="header-section-number">4.1</span> Steps of estimation</h3>
<p>We will first briefly introduce the steps of the analysis with the <code>seqHMM</code> package and then show examples of estimating MMs, HMMs, MMMs, and MHMMs.</p>
<section id="defining-the-model-structure" class="level4" data-number="4.1.1">
<h4 data-number="4.1.1" class="anchored" data-anchor-id="defining-the-model-structure"><span class="header-section-number">4.1.1</span> Defining the model structure</h4>
<p>First, we need to create the model object which defines the structure of the model. This can be done by using one of the model building functions of <code>seqHMM</code>. The build functions include <code>build_mm()</code> for constructing the simple MM, <code>build_hmm()</code> for the HMM, <code>build_mmm()</code> for the MMM, and <code>build_mhmm()</code> for the MHMM. The user needs to give the build function the sequence data and the number of hidden states and/or clusters (when relevant). The user can also set restrictions on the models, for example, to forbid some transitions by setting the corresponding transition probabilities to zero. To facilitate the estimation of the parameters of more complex models, the user may also set informative starting values for model parameters.</p>
</section>
<section id="estimating-the-model-parameters" class="level4" data-number="4.1.2">
<h4 data-number="4.1.2" class="anchored" data-anchor-id="estimating-the-model-parameters"><span class="header-section-number">4.1.2</span> Estimating the model parameters</h4>
<p>After defining the model structure, model parameters need to be estimated. The <code>fit_model()</code> function estimates model parameters using maximum likelihood estimation. The function has several arguments for configuring the estimation algorithms. For simple models the default arguments tend to work well enough, but for more complex models the user should adjust the algorithms. This is because the more parameters the algorithm needs to estimate, the higher the risk of not finding the model with the optimal parameter values (the one which maximises the likelihood).</p>
<p>In order to reduce the risk of being trapped in a local optimum of the likelihood surface (instead of a global optimum), we advise to estimate the model numerous times using different starting values for the parameters. The <code>seqHMM</code> package strives to automate this. One option is to run the EM algorithm multiple times with random starting values for any or all of initial, transition, and emission probabilities. These are specified in the <code>control_em</code> argument. Although not done by default, this method seems to perform very well as the EM algorithm is relatively fast. Another option is to use a global direct numerical estimation method such as the multilevel single-linkage method. See <span class="citation" data-cites="Helske2019">[<a href="#ref-Helske2019" role="doc-biblioref">4</a>]</span> for more detailed information on model estimation.</p>
</section>
<section id="examining-the-results" class="level4" data-number="4.1.3">
<h4 data-number="4.1.3" class="anchored" data-anchor-id="examining-the-results"><span class="header-section-number">4.1.3</span> Examining the results</h4>
<p>The output of the <code>fit_model</code> contains the estimated model (stored in <code>fit_hmm$model</code>) as well as information about the estimation of the model, such as the log-likelihood of the final model (<code>fit_hmm$logLik</code>). The <code>print</code> method provides information about the estimated model in a written format, while the <code>plot()</code> function visualises the model parameters as a graph. For HMMs and MHMMs, we can calculate the most probable sequence of hidden states for each individual with the <code>hidden_paths()</code> function. Sequences of observed and hidden state sequences can be plotted with the <code>ssplot()</code> function for MMs and HMMs and with the <code>mssplot()</code> function for the MMMs and the MHMMs. For MMMs and MHMMs, the <code>summary()</code> method automatically computes some features of the models such as standard errors for covariates and prior and posterior cluster membership probabilities for the subjects.</p>
</section>
</section>
<section id="markov" class="level3" data-number="4.2">
<h3 data-number="4.2" class="anchored" data-anchor-id="markov"><span class="header-section-number">4.2</span> Markov models</h3>
<p>We now follow the steps outlined above for each model in turn, starting from the most basic Markov model, proceeding through a hidden Markov model and a mixture Markov model, and finally concluding with a mixture hidden Markov model.</p>
<section id="markov-model-1" class="level4" data-number="4.2.1">
<h4 data-number="4.2.1" class="anchored" data-anchor-id="markov-model-1"><span class="header-section-number">4.2.1</span> Markov model</h4>
<p>We focus on the sequences of collaboration roles, collected in the <code>roles_seq</code> object. The <code>build_mm()</code> function only takes one argument, <code>observations</code>, which should be an <code>stslist</code> object created with the <code>seqdef()</code> function from the <code>TraMineR</code> package as mentioned before. We can build a MM as follows:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>markov_model <span class="ot">&lt;-</span> <span class="fu">build_mm</span>(roles_seq)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>For the MM, the <code>build_mm()</code> function estimates the initial probabilities and the transition matrix. Note that the <code>build_mm()</code> function is the only build function that automatically estimates the parameters of the model. This is possible because for the MM the estimation is a simple calculation while for the other types of models the estimation process is more complex. The user can access the estimated parameters by calling <code>markov_model$initial_probs</code> and <code>markov_model$transition_probs</code> or view them by using the print method of the model:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(markov_model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Initial probabilities :
 Isolate Mediator   Leader 
   0.375    0.355    0.270 

Transition probabilities :
          to
from       Isolate Mediator Leader
  Isolate   0.4231    0.478 0.0987
  Mediator  0.1900    0.563 0.2467
  Leader    0.0469    0.428 0.5252</code></pre>
</div>
</div>
<p>We can see that the initial state probabilities are relatively uniform, with a slightly lower probability for starting in the Leader state. In terms of the transition probabilities, the most distinct feature is that that it is rare to transition directly from the Leader state to Isolate and vice versa (estimated probabilities are about 5% and 10%, respectively). It is also more common to drop from Leader to Mediator (43%) than to increase collaboration from Mediator to Leader (25%). Similarly, the probability of moving from Mediator to Isolate is only 19 percent, but there is a 48 percent chance of transitioning from Isolate to Mediator.</p>
<p>We can also draw a graph of the estimated model using the <code>plot</code> method which by default shows the states as pie graphs (for the MM, the pie graphs only consist of one state), transition probabilities as directed arrows, and initial probabilities below each state (see <a href="#fig-mm-pie">Figure&nbsp;<span>12.3</span></a>).</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(markov_model, </span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">legend.prop =</span> <span class="fl">0.2</span>, <span class="at">ncol.legend =</span> <span class="dv">3</span>, </span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">edge.label.color =</span> <span class="st">"black"</span>, <span class="at">vertex.label.color =</span> <span class="st">"black"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-mm-pie" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="ch12-markov_files/figure-html/fig-mm-pie-1.png" class="img-fluid figure-img" width="768"></p>
<p></p><figcaption class="figure-caption"><strong>Figure</strong>&nbsp;3<strong>.</strong> Estimated Markov model as a pie charts with the transition probabilities shown as labelled edges.</figcaption><p></p>
</figure>
</div>
</div>
</div>
</section>
<section id="hidden-markov-models" class="level4" data-number="4.2.2">
<h4 data-number="4.2.2" class="anchored" data-anchor-id="hidden-markov-models"><span class="header-section-number">4.2.2</span> Hidden Markov models</h4>
<p>The structure of an HMM is set with the <code>build_hmm()</code> function. In contrast to <code>build_mm()</code>, other <code>build_*()</code> functions such as <code>build_hmm()</code> do not directly estimate the model parameters. For <code>build_hmm()</code>, in addition to observations (an <code>stslist</code>), we need to provide the <code>n_states</code> argument which tells the model how many hidden states to construct. Using again the collaboration roles sequences, if we want to estimate an HMM with two hidden states, we can write:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>hidden_markov_model <span class="ot">&lt;-</span> <span class="fu">build_hmm</span>(<span class="at">observations =</span> roles_seq, <span class="at">n_states =</span> <span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The <code>set.seed</code> call ensures that we will always end up with the same exact initial model with hidden states in the same exact order even though we use random values for the initial parameters of the model (which is practical for reproducibility). We are now ready to estimate the model with the <code>fit_model()</code> function. The HMM we want to estimate is simple, so we rely on the default values and again use the print method to provide information about the estimated model:</p>
<div class="cell" data-hash="ch12-markov_cache/html/unnamed-chunk-8_1bb285aa0bfd044e91766ade7d4f908f">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>fit_hmm <span class="ot">&lt;-</span> <span class="fu">fit_model</span>(hidden_markov_model)</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>fit_hmm<span class="sc">$</span>model</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Initial probabilities :
State 1 State 2 
  0.657   0.343 

Transition probabilities :
         to
from      State 1 State 2
  State 1  0.9089  0.0911
  State 2  0.0391  0.9609

Emission probabilities :
           symbol_names
state_names Isolate Mediator Leader
    State 1  0.4418    0.525 0.0336
    State 2  0.0242    0.478 0.4980</code></pre>
</div>
</div>
<p>The estimated initial state probabilities show that it is more probable to start from hidden state 1 than from hidden state 2 (66% vs.&nbsp;34%). The high transition probabilities on the diagonal of the transition matrix indicate that the students typically tend to stay in the hidden state they currently are in. Transition probabilities between the hidden states are relatively low and also asymmetric: it is more likely that students move from state 1 to state 2 than from state 2 to state 1. Looking at the emission matrices, we see that the role of the students in state 2 is mostly Leader or Mediator (emission probabilities are 50% and 48%). On the other hand, state 1 captures more of those occasions where students are isolated or exhibit at most a moderate level of participation (mediators). We can also visualise this with the <code>plot()</code> method of <code>seqHMM</code> (see <a href="#fig-hmm-pie">Figure&nbsp;<span>12.4</span></a>):</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(fit_hmm<span class="sc">$</span>model, </span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">ncol.legend =</span> <span class="dv">4</span>, <span class="at">legend.prop =</span> <span class="fl">0.2</span>, </span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">edge.label.color =</span> <span class="st">"black"</span>, <span class="at">vertex.label.color =</span> <span class="st">"black"</span></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-hmm-pie" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="ch12-markov_files/figure-html/fig-hmm-pie-1.png" class="img-fluid figure-img" width="768"></p>
<p></p><figcaption class="figure-caption"><strong>Figure</strong>&nbsp;4<strong>.</strong> HMM with two hidden states (pie charts), with transitions between hidden states shown as labelled edges.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>The plot values mainly shows the same information. By default, to simplify the graph, the plotting method combines all states with less than 5% emission probabilities into one category. This threshold can be changed with the <code>combine.slices</code> argument (setting <code>combine.slices = 0</code> plots all states).</p>
<p>For simple models, using <code>n_states</code> is sufficient. It automatically draws random starting values that are then used for the estimation of model parameters. However, as parameter estimation of HMMs and mixture models can be sensitive to starting values of parameters, it may be beneficial to provide starting values manually using the <code>initial_probs</code>, <code>transition_probs</code>, and <code>emission_probs</code> arguments. This is also necessary in case we want to define structural zeros for some of these components, e.g., if we want to restrict the initial probabilities so that each sequence starts from the same hidden state, or if we want to set an upper diagonal transition matrix, which means that the model does not allow transitioning back to previous states (this is called a left-to-right model) <span class="citation" data-cites="Helske2019">[<a href="#ref-Helske2019" role="doc-biblioref">4</a>]</span>. It is also possible to mix random and user-defined starting values by using <code>simulate_*()</code> functions (e.g.&nbsp;<code>simulate_transition_probs()</code>) for some of the model components and user-defined values for others.</p>
<p>In the following example we demonstrate estimating a three-state HMM with user-defined starting values for the initial state probabilities and the transition matrix but simulate starting values for the emission matrices. For simulating starting values with <code>simulate_emission_probs</code>, we need to define the number of hidden states, and the number of observed symbols, i.e., the length of the alphabet of the sequences.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Set seed for randomisation</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a><span class="do">## Initial state probability vector, must sum to one</span></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>init_probs <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">0.3</span>, <span class="fl">0.4</span>, <span class="fl">0.3</span>)</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a><span class="do">## a 3x3 transition matrix, each row should sum to one</span></span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>trans_probs <span class="ot">&lt;-</span> <span class="fu">rbind</span>(<span class="fu">c</span>(<span class="fl">0.8</span>, <span class="fl">0.15</span>, <span class="fl">0.05</span>), <span class="fu">c</span>(<span class="fl">0.2</span>, <span class="fl">0.6</span>, <span class="fl">0.2</span>), <span class="fu">c</span>(<span class="fl">0.05</span>, <span class="fl">0.15</span>, <span class="fl">0.8</span>))</span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a><span class="do">## Simulate emission probabilities</span></span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a>emission_probs <span class="ot">&lt;-</span> <span class="fu">simulate_emission_probs</span>(</span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">n_states =</span> <span class="dv">3</span>, <span class="at">n_symbols =</span> <span class="fu">length</span>(<span class="fu">alphabet</span>(roles_seq))</span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a><span class="do">## Build the HMM</span></span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a>hidden_markov_model_2 <span class="ot">&lt;-</span> <span class="fu">build_hmm</span>(</span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a>  roles_seq, <span class="at">initial_probs =</span> init_probs, <span class="at">transition_probs =</span> trans_probs,</span>
<span id="cb23-18"><a href="#cb23-18" aria-hidden="true" tabindex="-1"></a>  <span class="at">emission_probs =</span> emission_probs</span>
<span id="cb23-19"><a href="#cb23-19" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Our initial probabilities suggest that it is slightly more likely to start from the second hidden state than the first and the third. Furthermore, the starting values for the transition matrices suggest that staying in hidden states 1 and 3 is more likely than staying in hidden state 2. All non-zero probabilities are, however, mere suggestions and will be estimated with the <code>fit_model()</code> function. We now estimate this model 50 times with the EM algorithm using randomised starting values:</p>
<div class="cell" data-hash="ch12-markov_cache/html/unnamed-chunk-11_45e2900a05503bdb30afe4d17e3e601a">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>fit_hmm_2 <span class="ot">&lt;-</span> <span class="fu">fit_model</span>(hidden_markov_model_2, </span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">control_em =</span> <span class="fu">list</span>(<span class="at">restart =</span> <span class="fu">list</span>(<span class="at">times =</span> <span class="dv">50</span>))</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We can get the information on the EM estimation as follows:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>fit_hmm_2<span class="sc">$</span>em_results</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>$logLik
[1] -3546.155

$iterations
[1] 488

$change
[1] 9.947132e-11

$best_opt_restart
 [1] -3546.155 -3546.155 -3546.155 -3546.155 -3546.155 -3546.155 -3546.155
 [8] -3546.155 -3546.155 -3546.155 -3546.155 -3546.155 -3546.155 -3546.155
[15] -3546.155 -3546.155 -3546.155 -3546.155 -3546.155 -3546.155 -3546.155
[22] -3546.155 -3546.155 -3546.155 -3546.155</code></pre>
</div>
</div>
<p>The <code>loglik</code> element gives the log-likelihood of the final model. This value has no meaning on its own, but it can be used to compare HMMs with the same data and model structure (e.g., when estimating the same model from different starting values). The <code>iterations</code> and <code>change</code> arguments give information on the last EM estimation round: how many iterations were used until the (local) optimum was found and what was the change in the log-likelihood at the final step.</p>
<p>The most interesting element is the last one: <code>best_opt_restart</code> shows the likelihood for 25 (by default) of the best estimation rounds. We advise to always check these to make sure that the best model was found several times from different starting values: this way we can be fairly certain that we have found the actual maximum likelihood estimates of the model parameters (global optimum). In this case all of the 25 log-likelihood values are identical, meaning that it is likely that we have found the best possible model among all HMMs with three hidden states.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(fit_hmm_2<span class="sc">$</span>model, </span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">legend.prop =</span> <span class="fl">0.15</span>, <span class="at">ncol.legend =</span> <span class="dv">3</span>,</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">edge.label.color =</span> <span class="st">"black"</span>, <span class="at">vertex.label.color =</span> <span class="st">"black"</span>,</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">combine.slices =</span> <span class="dv">0</span>, <span class="at">trim =</span> <span class="fl">0.0001</span></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-hmm-2" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="ch12-markov_files/figure-html/fig-hmm-2-1.png" class="img-fluid figure-img" width="768"></p>
<p></p><figcaption class="figure-caption"><strong>Figure</strong>&nbsp;5<strong>.</strong> HMM with three hidden states (pie charts), with transitions between hidden states shown as labelled edges.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>Interpreting the results in <a href="#fig-hmm-2">Figure&nbsp;<span>12.5</span></a> we see that the first hidden state represents about equal amounts of isolate and mediator roles, the second hidden state represents mainly Leaders and some Mediator roles, and the third hidden state represents mainly Mediator roles and partly Leader roles. Interestingly, none of the students start as Mediator/Leader, while of the other two the Isolate/Mediator state is more typical (two thirds). There are no transitions from the first to the second state nor vice versa, and transition probabilities to the second state are considerably higher than away from it. In other words, it seems that the model has two different origin states and one destination state.</p>
<p>We can visualise the observed and/or hidden state sequences with the <code>ssplot()</code> function. The <code>ssplot()</code> function can take an <code>stslist</code> object or a model object of class <code>mm</code> or <code>hmm</code> (see <a href="#fig-hmm-ssplot">Figure&nbsp;<span>12.6</span></a>). Here we want to plot full sequence index plots (<code>type = "I"</code>) of both observed and hidden states (<code>plots = "both"</code>) and sort the sequences using multidimensional scaling of hidden states (<code>sortv = "mds.hidden"</code>). See the <code>seqHMM</code> manual and visualisation vignette for more information on the different plotting options.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ssplot</span>(fit_hmm_2<span class="sc">$</span>model, </span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Plot sequence index plot (full sequences)</span></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">type =</span> <span class="st">"I"</span>, </span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Plot observed and hidden state sequences</span></span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">plots =</span> <span class="st">"both"</span>, </span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Sort sequences by the scores of multidimensional scaling</span></span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">sortv =</span> <span class="st">"mds.hidden"</span>,</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>  <span class="co"># X axis tick labels</span></span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">xtlab =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">20</span></span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-hmm-ssplot" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="ch12-markov_files/figure-html/fig-hmm-ssplot-1.png" class="img-fluid figure-img" width="576"></p>
<p></p><figcaption class="figure-caption"><strong>Figure</strong>&nbsp;6<strong>.</strong> Observed and hidden state sequences from the HMM with three hidden states.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>By looking at the sequences, we can see that even though none of the students start in hidden state 3, the majority of them transition there. In the end, most students end up alternating between mediating and leadership roles.</p>
<p>Is the three-state model better than the two-state model? As already mentioned, we can use model selection criteria to test that. To make sure that the three-state model is the best, we also estimate a HMM with four hidden states and then use the Bayesian information criterion for comparing between the three models. Because the four-state model is more complex, we increase the number of re-estimation rounds for the EM algorithm to 100.</p>
<div class="cell" data-hash="ch12-markov_cache/html/unnamed-chunk-15_9e4fd7a27c24bc855852a652abce33d4">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Set seed for randomisation</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a><span class="do">## Build and estimate a HMM with four states</span></span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>hidden_markov_model_3 <span class="ot">&lt;-</span> <span class="fu">build_hmm</span>(roles_seq, <span class="at">n_states =</span> <span class="dv">4</span>)</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>fit_hmm_3 <span class="ot">&lt;-</span> <span class="fu">fit_model</span>(hidden_markov_model_3, </span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">control_em =</span> <span class="fu">list</span>(<span class="at">restart =</span> <span class="fu">list</span>(<span class="at">times =</span> <span class="dv">100</span>))</span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a>fit_hmm_3<span class="sc">$</span>em_results<span class="sc">$</span>best_opt_restart</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> [1] -3534.304 -3534.304 -3534.304 -3534.304 -3534.304 -3534.304 -3534.304
 [8] -3534.304 -3534.304 -3534.304 -3534.304 -3534.304 -3534.304 -3534.305
[15] -3534.305 -3534.306 -3534.308 -3534.310 -3534.332 -3534.335 -3534.335
[22] -3534.335 -3534.336 -3534.337 -3534.337</code></pre>
</div>
</div>
<p>The best model was found only 13 times out of 101 estimation rounds from randomised starting values. A cautious researcher might be wise to opt for a higher number of estimation rounds for increased certainty, but here we will proceed to calculating the BIC values.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="fu">BIC</span>(fit_hmm<span class="sc">$</span>model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 7430.028</code></pre>
</div>
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="fu">BIC</span>(fit_hmm_2<span class="sc">$</span>model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 7208.427</code></pre>
</div>
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="fu">BIC</span>(fit_hmm_3<span class="sc">$</span>model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 7259.37</code></pre>
</div>
</div>
<p>Generally speaking, the lower the BIC, the better the model. We can see that the three-state model (<code>fit_hmm_2</code>) has the lowest BIC value, so three clusters is the best choice (at least among HMMs with 2–4 hidden states).</p>
</section>
<section id="mixture-markov-models" class="level4" data-number="4.2.3">
<h4 data-number="4.2.3" class="anchored" data-anchor-id="mixture-markov-models"><span class="header-section-number">4.2.3</span> Mixture Markov models</h4>
<p>The MMM can be defined with the <code>build_mmm()</code> function. Similarly to HMMs, we need to either give the number of clusters with the <code>n_clusters</code> argument, which generates random starting values for the parameter estimates, or give starting values manually as <code>initial_probs</code> and <code>transition_probs</code>. Here we use random starting values:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Set seed for randomisation</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a><span class="do">## Define model structure (3 clusters)</span></span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a>mmm <span class="ot">&lt;-</span> <span class="fu">build_mmm</span>(roles_seq, <span class="at">n_clusters =</span> <span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Again, the model is estimated with the <code>fit_model()</code> function:</p>
<div class="cell" data-hash="ch12-markov_cache/html/unnamed-chunk-18_8154b7c7d85f483c612b7e7619ee2dc4">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>fit_mmm <span class="ot">&lt;-</span> <span class="fu">fit_model</span>(mmm)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The results for each cluster can be plotted one at a time (interactively, the default), or in one joint figure. Here we opt for the latter (see <a href="#fig-mmm-pie">Figure&nbsp;<span>12.7</span></a>). At the same time we also illustrate some other plotting options:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(fit_mmm<span class="sc">$</span>model, </span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Plot all clusters at the same time</span></span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">interactive =</span> <span class="cn">FALSE</span>, </span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Set the number of rows and columns for cluster plots (one row, three columns)</span></span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">nrow =</span> <span class="dv">1</span>, <span class="at">ncol =</span> <span class="dv">3</span>,</span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Omit legends</span></span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">with.legend =</span> <span class="cn">FALSE</span>, </span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Choose another layout for the vertices (see plot.igraph)</span></span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">layout =</span> layout_in_circle,</span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Omit pie graphs from vertices</span></span>
<span id="cb39-11"><a href="#cb39-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">pie =</span> <span class="cn">FALSE</span>,</span>
<span id="cb39-12"><a href="#cb39-12" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Set state colours</span></span>
<span id="cb39-13"><a href="#cb39-13" aria-hidden="true" tabindex="-1"></a>  <span class="at">vertex.label.color =</span> <span class="fu">c</span>(<span class="st">"black"</span>, <span class="st">"black"</span>, <span class="st">"white"</span>),</span>
<span id="cb39-14"><a href="#cb39-14" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Set state label colours</span></span>
<span id="cb39-15"><a href="#cb39-15" aria-hidden="true" tabindex="-1"></a>  <span class="at">vertex.color =</span> <span class="fu">cpal</span>(roles_seq),</span>
<span id="cb39-16"><a href="#cb39-16" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Increase the size of the circle</span></span>
<span id="cb39-17"><a href="#cb39-17" aria-hidden="true" tabindex="-1"></a>  <span class="at">vertex.size =</span> <span class="dv">80</span>,</span>
<span id="cb39-18"><a href="#cb39-18" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Plot state labels instead of initial probabilities</span></span>
<span id="cb39-19"><a href="#cb39-19" aria-hidden="true" tabindex="-1"></a>  <span class="at">vertex.label =</span> <span class="st">"names"</span>, </span>
<span id="cb39-20"><a href="#cb39-20" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Choose font colour for state labels</span></span>
<span id="cb39-21"><a href="#cb39-21" aria-hidden="true" tabindex="-1"></a>  <span class="at">vertex.label.color =</span> <span class="st">"black"</span>, </span>
<span id="cb39-22"><a href="#cb39-22" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Set state label in the centre of the circle</span></span>
<span id="cb39-23"><a href="#cb39-23" aria-hidden="true" tabindex="-1"></a>  <span class="at">vertex.label.dist =</span> <span class="dv">0</span>,</span>
<span id="cb39-24"><a href="#cb39-24" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Omit labels for transition probabilities</span></span>
<span id="cb39-25"><a href="#cb39-25" aria-hidden="true" tabindex="-1"></a>  <span class="at">edge.label =</span> <span class="cn">NA</span></span>
<span id="cb39-26"><a href="#cb39-26" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-mmm-pie" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="ch12-markov_files/figure-html/fig-mmm-pie-1.png" class="img-fluid figure-img" width="576"></p>
<p></p><figcaption class="figure-caption"><strong>Figure</strong>&nbsp;7<strong>.</strong> MMM with three clusters.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>The following code plots the sequence distribution plot of each cluster (<a href="#fig-mmm-mss">Figure&nbsp;<span>12.8</span></a>). In Cluster 1, we see low probabilities to downward mobility and high probabilities for upward mobility, so this cluster describes leadership trajectories. In Cluster 2, we can see that the thickest arrows lead to mediator and isolates roles, so this cluster describes trajectories with less central roles in collaboration. In Cluster 3, we see the highest transition probabilities for entering the mediator role but also some transitions from mediator to leader, so this cluster describes trajectories with more moderate levels of participation in comparison to cluster 1. This behavior is easier to see when visualising the sequences in their most probable clusters. The plot is interactive, so we need to hit ‘Enter’ on the console to generate each plot. Alternatively, we can specify which cluster we want to plot using the <code>which.plots</code> argument.</p>
<div>
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>cl1 <span class="ot">&lt;-</span> <span class="fu">mssplot</span>(fit_mmm<span class="sc">$</span>model, </span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Plot Y axis</span></span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">yaxis =</span> <span class="cn">TRUE</span>, </span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Legend position</span></span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">with.legend   =</span> <span class="st">"bottom"</span>,</span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Legend columns</span></span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">ncol.legend =</span> <span class="dv">3</span>,</span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Label for Y axis</span></span>
<span id="cb40-9"><a href="#cb40-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">ylab =</span> <span class="st">"Proportion"</span></span>
<span id="cb40-10"><a href="#cb40-10" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="fig-mmm-mss" class="cell quarto-layout-panel">
<figure class="figure">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-mmm-mss-1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="ch12-markov_files/figure-html/fig-mmm-mss-1.png" class="img-fluid figure-img" data-ref-parent="fig-mmm-mss" width="576"></p>
<p></p><figcaption class="figure-caption">(a) Cluster 1.</figcaption><p></p>
</figure>
</div>
</div>
<div class="cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-mmm-mss-2" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="ch12-markov_files/figure-html/fig-mmm-mss-2.png" class="img-fluid figure-img" data-ref-parent="fig-mmm-mss" width="576"></p>
<p></p><figcaption class="figure-caption">(b) Cluster 2.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-mmm-mss-3" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="ch12-markov_files/figure-html/fig-mmm-mss-3.png" class="img-fluid figure-img" data-ref-parent="fig-mmm-mss" width="576"></p>
<p></p><figcaption class="figure-caption">(c) Cluster 3.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p></p><figcaption class="figure-caption"><strong>Figure</strong>&nbsp;8<strong>.</strong> State distribution plots by most probable clusters estimated with the mixture Markov model.</figcaption><p></p>
</figure>
</div>
</div>
<p>We can add covariates to the model to explain cluster membership probabilities. For this, we need to provide a data frame (argument <code>data</code>) and the corresponding formula (argument <code>formula</code>). In the example data we use the data frame called <code>cov_data</code> that we created at the beginning of the tutorial with columns <code>ID</code> and <code>GPA</code>, where the order of the <code>ID</code> variable matches to that of the sequence data <code>roles_seq</code> (note that the <code>ID</code> variable is not used in the model building, so the user needs to make sure that both matrices are sorted by ID). We can now use the information about students’ GPA level as a predictor of the cluster memberships.</p>
<p>Numerical estimation of complex models from random starting values may lead to convergence issues and other problems in the estimation (you may, for example, get warnings about the EM algorithm failing). To avoid such issues, giving informative starting values is often helpful. This model is more complex than the model without covariates and estimation from random starting values leads to convergence issues (not shown here). To facilitate model estimation, we use the results from the previous MMM as informative starting values. Here we also remove the common intercept by adding <code>0</code> to the <code>formula</code>, which simplifies the interpretation of the covariate effects later (instead of comparing to a reference category, we get separate coefficients for each of the three GPA categories).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">98765</span>)</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>mmm_2 <span class="ot">&lt;-</span> <span class="fu">build_mmm</span>(</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>  roles_seq, </span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Starting values for initial probabilities</span></span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">initial_probs =</span> fit_mmm<span class="sc">$</span>model<span class="sc">$</span>initial_probs,</span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Starting values for transition probabilities</span></span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">transition_probs =</span> fit_mmm<span class="sc">$</span>model<span class="sc">$</span>transition_probs,</span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Data frame for covariates</span></span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> cov_data, </span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Formula for covariates (one-sided)</span></span>
<span id="cb41-11"><a href="#cb41-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">formula =</span> <span class="sc">~</span> <span class="dv">0</span> <span class="sc">+</span> GPA</span>
<span id="cb41-12"><a href="#cb41-12" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Again, the model is estimated with the <code>fit_model()</code> function. Here we use the EM algorithm with 50 restarts from random starting values:</p>
<div class="cell" data-hash="ch12-markov_cache/html/unnamed-chunk-22_a45cff98b152c6dff3d3cc40a8e34174">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">12345</span>)</span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>fit_mmm_2 <span class="ot">&lt;-</span> <span class="fu">fit_model</span>(</span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>  mmm_2, </span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a>  <span class="co"># EM with randomised restarts</span></span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">control_em =</span> <span class="fu">list</span>(</span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">restart =</span> <span class="fu">list</span>(</span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a>      <span class="co"># 50 restarts</span></span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a>      <span class="at">times =</span> <span class="dv">50</span>, </span>
<span id="cb42-9"><a href="#cb42-9" aria-hidden="true" tabindex="-1"></a>      <span class="co"># Store loglik values from all 50 + 1 estimation rounds</span></span>
<span id="cb42-10"><a href="#cb42-10" aria-hidden="true" tabindex="-1"></a>      <span class="at">n_optimum =</span> <span class="dv">51</span></span>
<span id="cb42-11"><a href="#cb42-11" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb42-12"><a href="#cb42-12" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb42-13"><a href="#cb42-13" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in fit_model(mmm_2, control_em = list(restart = list(times = 50, : EM
algorithm failed: Estimation of gamma coefficients failed due to singular
Hessian.</code></pre>
</div>
</div>
<p>The model was estimated 50 + 1 times (first from the starting values we provided and then from 50 randomised values). We get one warning about the EM algorithm failing. However, 50 estimation rounds were successful. We can check that the best model was found several times from different starting values (37 times, to be precise):</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>fit_mmm_2<span class="sc">$</span>em_results<span class="sc">$</span>best_opt_restart</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> [1] -3614.627 -3614.627 -3614.627 -3614.627 -3614.627 -3614.627 -3614.627
 [8] -3614.627 -3614.627 -3614.627 -3614.627 -3614.627 -3614.627 -3614.627
[15] -3614.627 -3614.627 -3614.627 -3614.627 -3614.627 -3614.627 -3614.627
[22] -3614.627 -3614.627 -3614.627 -3614.627 -3614.627 -3614.627 -3614.627
[29] -3614.627 -3614.627 -3614.627 -3614.627 -3614.627 -3614.627 -3614.627
[36] -3614.627 -3614.627 -3619.695 -3624.547 -3624.547 -3624.547 -3624.547
[43] -3624.547 -3624.547 -3624.547 -3624.547 -3624.547 -3624.547 -3631.328
[50] -3637.344      -Inf</code></pre>
</div>
</div>
<p>We can now be fairly certain that the optimal model has been found, and can proceed to interpreting the results. The clusters are very similar to what we found before. We can give the clusters more informative labels and then show state distribution plots in each cluster in <a href="#fig-mmm2-mss">Figure&nbsp;<span>12.9</span></a>:</p>
<div>
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cluster_names</span>(fit_mmm_2<span class="sc">$</span>model) <span class="ot">&lt;-</span> <span class="fu">c</span>(</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>  <span class="st">"Mainly leader"</span>, <span class="st">"Isolate/mediator"</span>, <span class="st">"Mediator/leader"</span></span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a><span class="fu">mssplot</span>(fit_mmm_2<span class="sc">$</span>model, <span class="at">with.legend =</span> <span class="st">"bottom"</span>, <span class="at">ncol.legend =</span> <span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="fig-mmm2-mss" class="cell quarto-layout-panel">
<figure class="figure">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-mmm2-mss-1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="ch12-markov_files/figure-html/fig-mmm2-mss-1.png" class="img-fluid figure-img" data-ref-parent="fig-mmm2-mss" width="576"></p>
<p></p><figcaption class="figure-caption">(a) Mainly leader.</figcaption><p></p>
</figure>
</div>
</div>
<div class="cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-mmm2-mss-2" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="ch12-markov_files/figure-html/fig-mmm2-mss-2.png" class="img-fluid figure-img" data-ref-parent="fig-mmm2-mss" width="576"></p>
<p></p><figcaption class="figure-caption">(b) Isolate/mediator.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-mmm2-mss-3" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="ch12-markov_files/figure-html/fig-mmm2-mss-3.png" class="img-fluid figure-img" data-ref-parent="fig-mmm2-mss" width="576"></p>
<p></p><figcaption class="figure-caption">(c) Mediator/leader.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p></p><figcaption class="figure-caption"><strong>Figure</strong>&nbsp;9<strong>.</strong> State distribution plots by most probable clusters estimated with the mixture Markov model with covariates.</figcaption><p></p>
</figure>
</div>
</div>
<p>The model summary shows information about parameter estimates of covariates and prior and posterior cluster membership probabilities (these refer to cluster membership probabilities before or after conditioning on the observed sequences, respectively):</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>summary_mmm_2 <span class="ot">&lt;-</span> <span class="fu">summary</span>(fit_mmm_2<span class="sc">$</span>model)</span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>summary_mmm_2</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Covariate effects :
Mainly leader is the reference.

Isolate/mediator :
           Estimate  Std. error
GPALow       1.9221       0.478
GPAMiddle    0.3901       0.314
GPAHigh     -0.0451       0.277

Mediator/leader :
           Estimate  Std. error
GPALow        1.670       0.487
GPAMiddle     0.411       0.312
GPAHigh      -0.667       0.332

Log-likelihood: -3614.627   BIC: 7461.487 

Means of prior cluster probabilities :
   Mainly leader Isolate/mediator  Mediator/leader 
           0.244            0.425            0.331 

Most probable clusters :
            Mainly leader  Isolate/mediator  Mediator/leader
count                  49                87               64
proportion          0.245             0.435             0.32

Classification table :
Mean cluster probabilities (in columns) by the most probable cluster (rows)

                 Mainly leader Isolate/mediator Mediator/leader
Mainly leader          0.91758          0.00136          0.0811
Isolate/mediator       0.00081          0.89841          0.1008
Mediator/leader        0.05902          0.10676          0.8342</code></pre>
</div>
</div>
<p>We will first interpret the information on prior and posterior cluster membership probabilities and then proceed to interpreting covariate effects. Firstly, the <code>means of prior cluster probabilities</code> give information on how likely each cluster is in the whole population of students (33% in Mediator, 24% in Leader, and 43% in Isolate). Secondly, <code>Most probable clusters</code> shows group sizes and proportions if each student would be classified into the cluster for which they have the highest cluster membership probability.</p>
<p>Thirdly, the <code>Classification table</code> shows mean cluster probabilities (in columns) by the most probable cluster (in rows). We can see that the clusters are fairly crisp (the certainty of cluster memberships are fairly high) because the membership probabilities are large in the diagonal of the table. The uncertainty of the classification is the highest for the Mediator/leader cluster (among those that had the highest membership probability in that cluster, average cluster memberships were 84% for the Mediator/leader cluster, 6% for the Mainly leader cluster, and 10% for the Isolate/mediator cluster) and the highest in the Mainly leader cluster (92% for the Mainly leader cluster, 8% for the Mediator/leader cluster, and 0.1% for the Isolate/mediator cluster).</p>
<p>The part titled <code>Covariate effects</code> shows the parameter estimates for the covariates. Interpretation of the values is similar to that of multinomial logistic regression, meaning that we can interpret the direction and uncertainty of the effect –relative to the reference cluster Mainly leader– but we cannot directly interpret the magnitude of the effects (the magnitudes are on log-odds scale). We can see that individuals with low GPA more often end up in the Isolate/mediator cluster and the Mediator/leader cluster in comparison to the Mainly leader cluster (i.e., the standard errors are small in comparison to the parameter estimates), while individuals with high GPA levels end up in the Mediator/leader cluster less often but are not more or less likely to end up in the Isolate/mediator cluster. For categorical covariates such as our <code>GPA</code> variable, we can also easily compute the prior cluster membership probabilities from the estimates with the following call:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="fu">exp</span>(fit_mmm_2<span class="sc">$</span>model<span class="sc">$</span>coefficients)<span class="sc">/</span><span class="fu">rowSums</span>(<span class="fu">exp</span>(fit_mmm_2<span class="sc">$</span>model<span class="sc">$</span>coefficients))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>          Mainly leader Isolate/mediator Mediator/leader
GPALow       0.07605453        0.5198587       0.4040868
GPAMiddle    0.25090105        0.3705958       0.3785031
GPAHigh      0.40497185        0.3870997       0.2079285</code></pre>
</div>
</div>
<p>The matrix shows the levels of the covariates in the rows and the clusters in the columns. Among the high-GPA students, 41 percent are classified as Mainly leaders, 39 percent as Isolate/mediators, and 21 percent as Mediator/leaders. Among middle-GPA students classification is relatively uniform (25% as Mainly leaders, 37% as Isolate/mediators and 38 Mediator/leaders) whereas most of the low-GPA students are classified as Isolate/mediators or Mediator/leaders (52% and 40%, respectively).</p>
<p>The summary object also calculates prior and posterior cluster memberships for each student. We omit them here, for brevity, but demonstrate that they can be obtained as follows:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a>prior_prob <span class="ot">&lt;-</span> summary_mmm_2<span class="sc">$</span>prior_cluster_probabilities</span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a>posterior_prob <span class="ot">&lt;-</span> summary_mmm_2<span class="sc">$</span>posterior_cluster_probabilities</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="mixture-hidden-markov-models-1" class="level4" data-number="4.2.4">
<h4 data-number="4.2.4" class="anchored" data-anchor-id="mixture-hidden-markov-models-1"><span class="header-section-number">4.2.4</span> Mixture hidden Markov models</h4>
<p>Finally, we will proceed to the most complex of the models, the MHMM.</p>
<p>For defining a MHMM, we use the <code>build_mhmm()</code> function. Again, we can use the argument <code>n_states</code> which is now a vector showing the number of hidden states in each cluster (the length of the vector defines the number of clusters). We will begin by estimating a MHMM with three clusters, each with two hidden states:</p>
<div class="cell">

</div>
<div class="cell" data-linewidth="80" data-hash="ch12-markov_cache/html/unnamed-chunk-29_6e6327d121c612c8fc7c7b89f307c72e">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a>mhmm <span class="ot">&lt;-</span> <span class="fu">build_mhmm</span>(</span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a>  roles_seq, </span>
<span id="cb52-4"><a href="#cb52-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">n_states =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">2</span>),</span>
<span id="cb52-5"><a href="#cb52-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> cov_data, </span>
<span id="cb52-6"><a href="#cb52-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">formula =</span> <span class="sc">~</span> <span class="dv">0</span> <span class="sc">+</span> GPA</span>
<span id="cb52-7"><a href="#cb52-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb52-8"><a href="#cb52-8" aria-hidden="true" tabindex="-1"></a>fit_mhmm <span class="ot">&lt;-</span> <span class="fu">fit_model</span>(mhmm)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-error">
<pre><code>Error in fit_model(mhmm): EM algorithm failed: Estimation of gamma coefficients
failed due to singular Hessian.</code></pre>
</div>
</div>
<p>In this case, we get an error message about the EM algorithm failing. This means that the algorithm was not able to find parameter estimates from the random starting values the <code>build_mhmm()</code> function generated and we need to adjust our code.</p>
<p>Starting values for the parameters of the MHMM can be given with the arguments <code>initial_probs</code>, <code>transition_probs</code>, and <code>emission_probs</code>. For the MHMM, these are lists of vectors and matrices, one for each cluster. We use the same number of hidden states (two) for each cluster. We define the initial values for the transition and emission probabilities as well as regression coefficients ourselves. We also restrict the initial state probabilities so that in each cluster every student is forced to start from the same (first) hidden state.</p>
<div class="cell" data-hash="ch12-markov_cache/html/unnamed-chunk-30_7e50769bedad0be12ad253b322cda5e6">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a><span class="do">## Set initial probabilities</span></span>
<span id="cb54-4"><a href="#cb54-4" aria-hidden="true" tabindex="-1"></a>init <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">0</span>), <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">0</span>), <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">0</span>))</span>
<span id="cb54-5"><a href="#cb54-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-6"><a href="#cb54-6" aria-hidden="true" tabindex="-1"></a><span class="do">## Define own transition probabilities</span></span>
<span id="cb54-7"><a href="#cb54-7" aria-hidden="true" tabindex="-1"></a>trans <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">c</span>(</span>
<span id="cb54-8"><a href="#cb54-8" aria-hidden="true" tabindex="-1"></a>  <span class="fl">0.9</span>, <span class="fl">0.1</span>,</span>
<span id="cb54-9"><a href="#cb54-9" aria-hidden="true" tabindex="-1"></a>  <span class="fl">0.1</span>, <span class="fl">0.9</span></span>
<span id="cb54-10"><a href="#cb54-10" aria-hidden="true" tabindex="-1"></a>), <span class="at">nrow =</span> <span class="dv">2</span>, <span class="at">byrow =</span> <span class="cn">TRUE</span>)</span>
<span id="cb54-11"><a href="#cb54-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-12"><a href="#cb54-12" aria-hidden="true" tabindex="-1"></a>translist <span class="ot">&lt;-</span> <span class="fu">list</span>(trans, trans, trans)</span>
<span id="cb54-13"><a href="#cb54-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-14"><a href="#cb54-14" aria-hidden="true" tabindex="-1"></a><span class="do">## Simulate emission probabilities</span></span>
<span id="cb54-15"><a href="#cb54-15" aria-hidden="true" tabindex="-1"></a>emiss <span class="ot">&lt;-</span> <span class="fu">simulate_emission_probs</span>(</span>
<span id="cb54-16"><a href="#cb54-16" aria-hidden="true" tabindex="-1"></a>  <span class="at">n_states =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">2</span>), </span>
<span id="cb54-17"><a href="#cb54-17" aria-hidden="true" tabindex="-1"></a>  <span class="at">n_symbols =</span> <span class="dv">3</span>, </span>
<span id="cb54-18"><a href="#cb54-18" aria-hidden="true" tabindex="-1"></a>  <span class="at">n_clusters =</span> <span class="dv">3</span></span>
<span id="cb54-19"><a href="#cb54-19" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb54-20"><a href="#cb54-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-21"><a href="#cb54-21" aria-hidden="true" tabindex="-1"></a>emiss <span class="ot">&lt;-</span> <span class="fu">replicate</span>(<span class="dv">3</span>, <span class="fu">matrix</span>(<span class="dv">1</span><span class="sc">/</span><span class="dv">3</span>, <span class="dv">2</span>, <span class="dv">3</span>), <span class="at">simplify =</span> <span class="cn">FALSE</span>)</span>
<span id="cb54-22"><a href="#cb54-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-23"><a href="#cb54-23" aria-hidden="true" tabindex="-1"></a><span class="do">## Define initial values for coefficients</span></span>
<span id="cb54-24"><a href="#cb54-24" aria-hidden="true" tabindex="-1"></a><span class="do">## Here we start from a case where low GPA correlates with Cluster 1, </span></span>
<span id="cb54-25"><a href="#cb54-25" aria-hidden="true" tabindex="-1"></a><span class="do">## whereas middle and high GPA has no effect</span></span>
<span id="cb54-26"><a href="#cb54-26" aria-hidden="true" tabindex="-1"></a>beta <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="dv">0</span>, <span class="fu">c</span>(<span class="sc">-</span><span class="dv">2</span>, <span class="dv">0</span>, <span class="dv">0</span>), <span class="fu">c</span>(<span class="sc">-</span><span class="dv">2</span>, <span class="dv">0</span>, <span class="dv">0</span>))</span>
<span id="cb54-27"><a href="#cb54-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-28"><a href="#cb54-28" aria-hidden="true" tabindex="-1"></a><span class="do">## Define model structure</span></span>
<span id="cb54-29"><a href="#cb54-29" aria-hidden="true" tabindex="-1"></a>mhmm_2 <span class="ot">&lt;-</span> <span class="fu">build_mhmm</span>(</span>
<span id="cb54-30"><a href="#cb54-30" aria-hidden="true" tabindex="-1"></a>  roles_seq, </span>
<span id="cb54-31"><a href="#cb54-31" aria-hidden="true" tabindex="-1"></a>  <span class="at">initial_probs =</span> init, <span class="at">transition_probs =</span> translist, </span>
<span id="cb54-32"><a href="#cb54-32" aria-hidden="true" tabindex="-1"></a>  <span class="at">emission_probs =</span> emiss, <span class="at">data =</span> cov_data, </span>
<span id="cb54-33"><a href="#cb54-33" aria-hidden="true" tabindex="-1"></a>  <span class="at">formula =</span> <span class="sc">~</span> <span class="dv">0</span> <span class="sc">+</span> GPA, <span class="at">beta =</span> beta</span>
<span id="cb54-34"><a href="#cb54-34" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now that we have built the MHMM, we can estimate its parameters:</p>
<div class="cell" data-hash="ch12-markov_cache/html/unnamed-chunk-31_485f1154e018038d94955f375e41d7de">
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a><span class="fu">suppressWarnings</span>(fit_mhmm_2 <span class="ot">&lt;-</span> <span class="fu">fit_model</span>(</span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a>  mhmm_2,</span>
<span id="cb55-4"><a href="#cb55-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">control_em =</span> <span class="fu">list</span>(<span class="at">restart =</span> <span class="fu">list</span>(<span class="at">times =</span> <span class="dv">100</span>, <span class="at">n_optimum =</span> <span class="dv">101</span>)))</span>
<span id="cb55-5"><a href="#cb55-5" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We can now check how many times the log-likelihood values occurred in the 101 estimations:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(<span class="fu">round</span>(fit_mhmm_2<span class="sc">$</span>em_results<span class="sc">$</span>best_opt_restart, <span class="dv">2</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
    -Inf -3672.25 -3595.82 -3588.58 -3584.14 -3526.42 -3525.06 -3519.53 
      56        2        1        3        1        4        1        2 
 -3519.5 -3519.24 
      15       16 </code></pre>
</div>
</div>
<p>The best model was found 16 times out of 101 times, although the second beset model with log-likelihood of -3519.5 is likely almost indistinguishable from the optimal model (-3519.24) as their log-likelihoods are so close to each other.</p>
<p>We will start to interpret the model by looking at the sequence plots in each cluster (see <a href="#fig-mhmm-seq">Figure&nbsp;<span>12.10</span></a>). The function call is interactive. As before, if you only want to plot one cluster you can use the <code>which.plots</code> argument:</p>
<div>
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mssplot</span>(fit_mhmm_2<span class="sc">$</span>model, </span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a>        <span class="at">plots =</span> <span class="st">"both"</span>, <span class="at">type =</span> <span class="st">"I"</span>, <span class="at">sortv =</span> <span class="st">"mds.hidden"</span>, </span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true" tabindex="-1"></a>        <span class="at">with.legend =</span> <span class="st">"bottom.combined"</span>, <span class="at">legend.prop =</span> .<span class="dv">15</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="fig-mhmm-seq" class="cell quarto-layout-panel">
<figure class="figure">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 33.3%;justify-content: center;">
<div id="fig-mhmm-seq-1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="ch12-markov_files/figure-html/fig-mhmm-seq-1.png" class="img-fluid figure-img" data-ref-parent="fig-mhmm-seq" width="441"></p>
<p></p><figcaption class="figure-caption">(a) Cluster 1</figcaption><p></p>
</figure>
</div>
</div>
<div class="cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 33.3%;justify-content: center;">
<div id="fig-mhmm-seq-2" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="ch12-markov_files/figure-html/fig-mhmm-seq-2.png" class="img-fluid figure-img" data-ref-parent="fig-mhmm-seq" width="441"></p>
<p></p><figcaption class="figure-caption">(b) Cluster 2</figcaption><p></p>
</figure>
</div>
</div>
<div class="cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 33.3%;justify-content: center;">
<div id="fig-mhmm-seq-3" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="ch12-markov_files/figure-html/fig-mhmm-seq-3.png" class="img-fluid figure-img" data-ref-parent="fig-mhmm-seq" width="441"></p>
<p></p><figcaption class="figure-caption">(c) Cluster 3</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p></p><figcaption class="figure-caption"><strong>Figure</strong>&nbsp;10<strong>.</strong> MHMM estimated sequence distribution plot with hidden states.</figcaption><p></p>
</figure>
</div>
</div>
<p>We can also visualise the model parameters in each cluster (see <a href="#fig-mhmm-pie">Figure&nbsp;<span>12.11</span></a>):</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(fit_mhmm_2<span class="sc">$</span>model, </span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">vertex.size =</span> <span class="dv">60</span>,</span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">label.color =</span> <span class="st">"black"</span>,</span>
<span id="cb59-4"><a href="#cb59-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">vertex.label.color =</span> <span class="st">"black"</span>,</span>
<span id="cb59-5"><a href="#cb59-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">edge.color =</span> <span class="st">"lightgray"</span>,</span>
<span id="cb59-6"><a href="#cb59-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">edge.label.color =</span> <span class="st">"black"</span>,</span>
<span id="cb59-7"><a href="#cb59-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">legend.prop =</span> <span class="fl">0.4</span>,</span>
<span id="cb59-8"><a href="#cb59-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">ncol.legend =</span> <span class="dv">1</span>, </span>
<span id="cb59-9"><a href="#cb59-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">ncol =</span> <span class="dv">3</span>,</span>
<span id="cb59-10"><a href="#cb59-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">interactive =</span> <span class="cn">FALSE</span>,</span>
<span id="cb59-11"><a href="#cb59-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">combine.slices =</span> <span class="dv">0</span></span>
<span id="cb59-12"><a href="#cb59-12" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-mhmm-pie" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="ch12-markov_files/figure-html/fig-mhmm-pie-1.png" class="img-fluid figure-img" width="800"></p>
<p></p><figcaption class="figure-caption"><strong>Figure</strong>&nbsp;11<strong>.</strong> Transitions between states for each trajectory.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>Based on the two plots, we can determine that Cluster 1 describes students who start as leaders but then transition to alternating between mediator and leader. Cluster 2 describes students who start by alternating between isolate and mediator roles and then mainly transition to alternating between mediator and leader roles. Cluster 3 describes students who start as alternating between isolate and mediator roles, after which they transition between isolate/mediator and mediator/leader.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cluster_names</span>(fit_mhmm_2<span class="sc">$</span>model) <span class="ot">&lt;-</span> <span class="fu">c</span>(</span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a>  <span class="st">"Downward transition"</span>, <span class="st">"Upward transition"</span>, <span class="st">"Alternating"</span></span>
<span id="cb60-3"><a href="#cb60-3" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>With <code>summary(fit_mhmm_2$model)</code> we get the parameter estimates and standard errors for the covariates and information about clustering:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fit_mhmm_2<span class="sc">$</span>model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Covariate effects :
Downward transition is the reference.

Upward transition :
           Estimate  Std. error
GPALow       -0.455       0.464
GPAMiddle     0.440       0.310
GPAHigh      -2.743       0.727

Alternating :
           Estimate  Std. error
GPALow       1.3560       0.324
GPAMiddle    0.3461       0.316
GPAHigh      0.0468       0.250

Log-likelihood: -3519.243   BIC: 7237.543 

Means of prior cluster probabilities :
Downward transition   Upward transition         Alternating 
              0.302               0.181               0.517 

Most probable clusters :
            Downward transition  Upward transition  Alternating
count                        61                 30          109
proportion                0.305               0.15        0.545

Classification table :
Mean cluster probabilities (in columns) by the most probable cluster (rows)

                    Downward transition Upward transition Alternating
Downward transition             0.95727            0.0267      0.0161
Upward transition               0.03007            0.8037      0.1662
Alternating                     0.00975            0.0962      0.8940</code></pre>
</div>
</div>
<p>We can see, that the prior probabilities of belonging to each cluster are very different: half of the students can be described as alternating, while of the rest, a downward transition is more typical (31%). Based on the classification table, the Downward transition cluster is rather crisp, while the other two are partly overlapping (see the MMM example for more information on interpreting the classification table).</p>
<p>The <code>Covariate effects</code> tables show that, in comparison to Alternating cluster, students with low GPA are less likely to end up in the Upward or Downward transition clusters and students with high GPA are less likely to end up in Upward transition cluster. Again, we can calculate the probabilities of belonging to each cluster by GPA levels:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="fu">exp</span>(fit_mhmm_2<span class="sc">$</span>model<span class="sc">$</span>coefficients)<span class="sc">/</span><span class="fu">rowSums</span>(<span class="fu">exp</span>(fit_mhmm_2<span class="sc">$</span>model<span class="sc">$</span>coefficients))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>          Downward transition Upward transition Alternating
GPALow              0.1813217        0.11502283   0.7036555
GPAMiddle           0.2521406        0.39144399   0.3564154
GPAHigh             0.4734128        0.03048189   0.4961054</code></pre>
</div>
</div>
<p>The table shows that students with low GPA typically belong to the Alternating cluster (70 % probability) while students with high GPA mainly end up in the Downward transition cluster (47%) or the Alternating cluster (50%). Most students with middle GPA end up in the Upward transition cluster (39%), but the probabilities are almost as high for the Alternating cluster (36%) and also fairly high for the Downward transition cluster (25%).</p>
<p>In light of this, it is worth noting that the covariates do not merely explain the uncovered clusters; as part of the model, they drive the formation of the clusters. In other words, an otherwise identical model without the dependence on the <code>GPA</code> covariate may uncover different groupings with different probabilities.</p>
<p>If we are not sure how many clusters or hidden states we expect, or if we wish to investigate different combinations of covariates, we can estimate several models and compare the results with information criteria or cross-validation. Estimating a large number of complex models is, however, very time-consuming. Using prior information for restricting the pool of potential models is useful, and sequence analysis can also be used as a helpful first step <span class="citation" data-cites="Helske2018 Helske2023">[<a href="#ref-Helske2018" role="doc-biblioref">10</a>, <a href="#ref-Helske2023" role="doc-biblioref">37</a>]</span>.</p>
</section>
</section>
<section id="process" class="level3" data-number="4.3">
<h3 data-number="4.3" class="anchored" data-anchor-id="process"><span class="header-section-number">4.3</span> Stochastic process mining with Markovian models</h3>
<p>Process miming is a relatively recent method for the analysis of event-log data (time-stamped logs) which aims to understand the flow and dynamics of the process under study. In education, process mining has been used extensively to analyse learners’ online logs collected from Learning Management Systems (LMS), to understand how they utilize learning resources and transitions between learning activities to mention a few <span class="citation" data-cites="peeters2020applying saqr2022transferring">[<a href="#ref-peeters2020applying" role="doc-biblioref">38</a>, <a href="#ref-saqr2022transferring" role="doc-biblioref">39</a>]</span>. In this book, we have devoted a full chapter for process mining where we explained how process mining can be performed in R <span class="citation" data-cites="Lopez-Pernas2024-as">[<a href="#ref-Lopez-Pernas2024-as" role="doc-biblioref">40</a>]</span>. Yet, in this chapter we will present a novel method that we propose to perform stochastic process mining using MMs. While process mining can be performed using different software, techniques and algorithms, MMs offer a powerful framework for process mining with several advantages over the commonly used methods. First, it is more theoretically aligned with the idea of a transition from an action to an action and that actions are temporally dependent on each other. Second, MMs allow for data to be clustered into similar transition patterns, a possibility not offered by other process mining methods (see the process mining chapter of this book <span class="citation" data-cites="Lopez-Pernas2024-as">[<a href="#ref-Lopez-Pernas2024-as" role="doc-biblioref">40</a>]</span>). Third, contrary to other process mining methods, MMs do not require researchers to arbitrarily exclude —or trim— a large part of the data to “simplify” the model. For instance, most of the process mining analyses require an arbitrary cutoff to trim the data so that the process model is readable. This trimming signficaintly affect the resulting model and makes it hard to replicate. Most importantly, MMs have several fit statistics that we can use to compare and judge the model fit as we have seen before.</p>
<p>Several R packages can perform stochastic process mining; in this tutorial we will rely on the same package we discussed earlier and combine it with a powerful visualization that allows us to effectively visualize complex processes. In the next example, we will analyse data extracted from the learning management system logs and offer a detailed guide to process mining. We will also use MMMs to cluster the data into latent patterns of transitions. Given that the traditional plotting function in <code>seqHMM</code> works well with a relatively short alphabet, we will use a new R package called <code>qgraph</code> for plotting. The package <code>qgraph</code> offers powerful visualizations which makes plotting easier, and more interpretable especially for larger models. Furthermore, <code>qgraph</code> allows researchers to use a fixed layout for all the plotted networks so the nodes can be compared to each other more easily.</p>
<p>Let us now go through the analysis. The next chunk of code imports the prepared sequence data from the sequence analysis chapter. The data belong to a learning analytics course and the events are coded trace logs of students’ actions such as <em>Course view</em>, <em>Instructions</em>, <em>Practicals</em>, <em>Social</em>, etc. Then, we build a sequence object using the function <code>seqdef()</code> from <code>TraMineR</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a>seq_data <span class="ot">&lt;-</span> <span class="fu">import</span>(<span class="fu">paste0</span>(URL, <span class="st">"1_moodleLAcourse/LMS_data_wide.xlsx"</span>))</span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a>seq_data_all <span class="ot">&lt;-</span> <span class="fu">seqdef</span>(seq_data, <span class="at">var =</span> <span class="dv">7</span><span class="sc">:</span><span class="dv">54</span> )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Before proceeding further, it is advisable to visualise the sequences. <a href="#fig-process-index">Figure&nbsp;<span>12.12</span></a> shows the sequence index plot, sorted according to the first states. The data are much larger than the collaboration roles and achievement sequences analysed previously; there are 9478 observations with an alphabet of 12 states. Unlike in the previous example, the sequence lengths vary considerably. Due to this, shorter sequences contain missing values to fill the empty cells in the data frame. However, there are no internal gaps. When creating the sequence object with the <code>seqdef</code> function, <code>TraMineR</code> allows for distinguishing between real missing values (<code>NA</code>, where the true state is unknown) and technical missing values (void) used to pad the sequences to equal lengths. The <code>seqHMM</code> package is able to account for both types of missing values and treats them slightly differently, for example when calculating the most probable paths of hidden states.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="fu">seqplot</span>(seq_data_all, </span>
<span id="cb66-2"><a href="#cb66-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">type =</span> <span class="st">"I"</span>, <span class="at">ncol =</span> <span class="dv">4</span>, <span class="at">sortv =</span> <span class="st">"from.start"</span>,</span>
<span id="cb66-3"><a href="#cb66-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">legend.prop =</span> <span class="fl">0.2</span>, <span class="at">cex.legend =</span> <span class="fl">0.7</span>, <span class="at">border =</span> <span class="cn">NA</span>,</span>
<span id="cb66-4"><a href="#cb66-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">ylab =</span> <span class="st">"Sequence (sorted)"</span>, <span class="at">xlab =</span> <span class="st">"Time"</span></span>
<span id="cb66-5"><a href="#cb66-5" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-process-index" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="ch12-markov_files/figure-html/fig-process-index-1.png" class="img-fluid figure-img" width="1500"></p>
<p></p><figcaption class="figure-caption"><strong>Figure</strong>&nbsp;12<strong>.</strong> Sequence index plot for the learning management system logs.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>A simple transition analysis can be performed by estimating and plotting the transition probabilities. This can be performed using the <code>TraMineR</code> package. Yet, this simple approach has drawbacks and it is advisable to estimate the MM and use their full power. The next code estimates the transition probabilities of the full dataset and visualize them using the function <code>seqtrate()</code> from <code>TraMineR</code> package.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a>overalltransitions <span class="ot">&lt;-</span> <span class="fu">seqtrate</span>(seq_data_all)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="tbl-transition" class="anchored">

<div id="evfpiyyuom" style="padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>#evfpiyyuom table {
  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}

#evfpiyyuom thead, #evfpiyyuom tbody, #evfpiyyuom tfoot, #evfpiyyuom tr, #evfpiyyuom td, #evfpiyyuom th {
  border-style: none;
}

#evfpiyyuom p {
  margin: 0;
  padding: 0;
}

#evfpiyyuom .gt_table {
  display: table;
  border-collapse: collapse;
  line-height: normal;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: tiny;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#evfpiyyuom .gt_caption {
  padding-top: 4px;
  padding-bottom: 4px;
}

#evfpiyyuom .gt_title {
  color: #333333;
  font-size: tiny;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#evfpiyyuom .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 3px;
  padding-bottom: 5px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#evfpiyyuom .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#evfpiyyuom .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#evfpiyyuom .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#evfpiyyuom .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#evfpiyyuom .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#evfpiyyuom .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#evfpiyyuom .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#evfpiyyuom .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 5px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#evfpiyyuom .gt_spanner_row {
  border-bottom-style: hidden;
}

#evfpiyyuom .gt_group_heading {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  text-align: left;
}

#evfpiyyuom .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#evfpiyyuom .gt_from_md > :first-child {
  margin-top: 0;
}

#evfpiyyuom .gt_from_md > :last-child {
  margin-bottom: 0;
}

#evfpiyyuom .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#evfpiyyuom .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
}

#evfpiyyuom .gt_stub_row_group {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
  vertical-align: top;
}

#evfpiyyuom .gt_row_group_first td {
  border-top-width: 2px;
}

#evfpiyyuom .gt_row_group_first th {
  border-top-width: 2px;
}

#evfpiyyuom .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#evfpiyyuom .gt_first_summary_row {
  border-top-style: solid;
  border-top-color: #D3D3D3;
}

#evfpiyyuom .gt_first_summary_row.thick {
  border-top-width: 2px;
}

#evfpiyyuom .gt_last_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#evfpiyyuom .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#evfpiyyuom .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#evfpiyyuom .gt_last_grand_summary_row_top {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: double;
  border-bottom-width: 6px;
  border-bottom-color: #D3D3D3;
}

#evfpiyyuom .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#evfpiyyuom .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#evfpiyyuom .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#evfpiyyuom .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#evfpiyyuom .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#evfpiyyuom .gt_sourcenote {
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#evfpiyyuom .gt_left {
  text-align: left;
}

#evfpiyyuom .gt_center {
  text-align: center;
}

#evfpiyyuom .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#evfpiyyuom .gt_font_normal {
  font-weight: normal;
}

#evfpiyyuom .gt_font_bold {
  font-weight: bold;
}

#evfpiyyuom .gt_font_italic {
  font-style: italic;
}

#evfpiyyuom .gt_super {
  font-size: 65%;
}

#evfpiyyuom .gt_footnote_marks {
  font-size: 75%;
  vertical-align: 0.4em;
  position: initial;
}

#evfpiyyuom .gt_asterisk {
  font-size: 100%;
  vertical-align: 0;
}

#evfpiyyuom .gt_indent_1 {
  text-indent: 5px;
}

#evfpiyyuom .gt_indent_2 {
  text-indent: 10px;
}

#evfpiyyuom .gt_indent_3 {
  text-indent: 15px;
}

#evfpiyyuom .gt_indent_4 {
  text-indent: 20px;
}

#evfpiyyuom .gt_indent_5 {
  text-indent: 25px;
}
</style>
<table class="gt_table" data-quarto-disable-processing="false" data-quarto-bootstrap="false"><caption>Table&nbsp;7.  Transition probabilities </caption>
  <thead>
    
    <tr class="gt_col_headings">
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1" scope="col" id="From\To">From\To</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" scope="col" id="Applications">Applications</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" scope="col" id="Assignment">Assignment</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" scope="col" id="Course_view">Course_view</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" scope="col" id="Ethics">Ethics</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" scope="col" id="Feedback">Feedback</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" scope="col" id="General">General</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" scope="col" id="Group_work">Group_work</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" scope="col" id="Instructions">Instructions</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" scope="col" id="La_types">La_types</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" scope="col" id="Practicals">Practicals</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" scope="col" id="Social">Social</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" scope="col" id="Theory">Theory</th>
    </tr>
  </thead>
  <tbody class="gt_table_body">
    <tr><td headers="From\To" class="gt_row gt_left">Applications</td>
<td headers="Applications" class="gt_row gt_right">0.46</td>
<td headers="Assignment" class="gt_row gt_right">0.07</td>
<td headers="Course_view" class="gt_row gt_right">0.13</td>
<td headers="Ethics" class="gt_row gt_right">0.01</td>
<td headers="Feedback" class="gt_row gt_right">0.01</td>
<td headers="General" class="gt_row gt_right">0.19</td>
<td headers="Group_work" class="gt_row gt_right">0.05</td>
<td headers="Instructions" class="gt_row gt_right">0.01</td>
<td headers="La_types" class="gt_row gt_right">0.01</td>
<td headers="Practicals" class="gt_row gt_right">0.05</td>
<td headers="Social" class="gt_row gt_right">0.00</td>
<td headers="Theory" class="gt_row gt_right">0.00</td></tr>
    <tr><td headers="From\To" class="gt_row gt_left">Assignment</td>
<td headers="Applications" class="gt_row gt_right">0.00</td>
<td headers="Assignment" class="gt_row gt_right">0.70</td>
<td headers="Course_view" class="gt_row gt_right">0.19</td>
<td headers="Ethics" class="gt_row gt_right">0.00</td>
<td headers="Feedback" class="gt_row gt_right">0.01</td>
<td headers="General" class="gt_row gt_right">0.02</td>
<td headers="Group_work" class="gt_row gt_right">0.03</td>
<td headers="Instructions" class="gt_row gt_right">0.02</td>
<td headers="La_types" class="gt_row gt_right">0.02</td>
<td headers="Practicals" class="gt_row gt_right">0.02</td>
<td headers="Social" class="gt_row gt_right">0.00</td>
<td headers="Theory" class="gt_row gt_right">0.00</td></tr>
    <tr><td headers="From\To" class="gt_row gt_left">Course_view</td>
<td headers="Applications" class="gt_row gt_right">0.01</td>
<td headers="Assignment" class="gt_row gt_right">0.07</td>
<td headers="Course_view" class="gt_row gt_right">0.35</td>
<td headers="Ethics" class="gt_row gt_right">0.01</td>
<td headers="Feedback" class="gt_row gt_right">0.03</td>
<td headers="General" class="gt_row gt_right">0.03</td>
<td headers="Group_work" class="gt_row gt_right">0.28</td>
<td headers="Instructions" class="gt_row gt_right">0.10</td>
<td headers="La_types" class="gt_row gt_right">0.02</td>
<td headers="Practicals" class="gt_row gt_right">0.08</td>
<td headers="Social" class="gt_row gt_right">0.02</td>
<td headers="Theory" class="gt_row gt_right">0.01</td></tr>
    <tr><td headers="From\To" class="gt_row gt_left">Ethics</td>
<td headers="Applications" class="gt_row gt_right">0.01</td>
<td headers="Assignment" class="gt_row gt_right">0.00</td>
<td headers="Course_view" class="gt_row gt_right">0.12</td>
<td headers="Ethics" class="gt_row gt_right">0.61</td>
<td headers="Feedback" class="gt_row gt_right">0.01</td>
<td headers="General" class="gt_row gt_right">0.04</td>
<td headers="Group_work" class="gt_row gt_right">0.10</td>
<td headers="Instructions" class="gt_row gt_right">0.01</td>
<td headers="La_types" class="gt_row gt_right">0.03</td>
<td headers="Practicals" class="gt_row gt_right">0.04</td>
<td headers="Social" class="gt_row gt_right">0.01</td>
<td headers="Theory" class="gt_row gt_right">0.02</td></tr>
    <tr><td headers="From\To" class="gt_row gt_left">Feedback</td>
<td headers="Applications" class="gt_row gt_right">0.00</td>
<td headers="Assignment" class="gt_row gt_right">0.02</td>
<td headers="Course_view" class="gt_row gt_right">0.23</td>
<td headers="Ethics" class="gt_row gt_right">0.00</td>
<td headers="Feedback" class="gt_row gt_right">0.56</td>
<td headers="General" class="gt_row gt_right">0.00</td>
<td headers="Group_work" class="gt_row gt_right">0.11</td>
<td headers="Instructions" class="gt_row gt_right">0.04</td>
<td headers="La_types" class="gt_row gt_right">0.01</td>
<td headers="Practicals" class="gt_row gt_right">0.02</td>
<td headers="Social" class="gt_row gt_right">0.00</td>
<td headers="Theory" class="gt_row gt_right">0.00</td></tr>
    <tr><td headers="From\To" class="gt_row gt_left">General</td>
<td headers="Applications" class="gt_row gt_right">0.04</td>
<td headers="Assignment" class="gt_row gt_right">0.05</td>
<td headers="Course_view" class="gt_row gt_right">0.18</td>
<td headers="Ethics" class="gt_row gt_right">0.01</td>
<td headers="Feedback" class="gt_row gt_right">0.00</td>
<td headers="General" class="gt_row gt_right">0.49</td>
<td headers="Group_work" class="gt_row gt_right">0.06</td>
<td headers="Instructions" class="gt_row gt_right">0.06</td>
<td headers="La_types" class="gt_row gt_right">0.05</td>
<td headers="Practicals" class="gt_row gt_right">0.03</td>
<td headers="Social" class="gt_row gt_right">0.01</td>
<td headers="Theory" class="gt_row gt_right">0.02</td></tr>
    <tr><td headers="From\To" class="gt_row gt_left">Group_work</td>
<td headers="Applications" class="gt_row gt_right">0.00</td>
<td headers="Assignment" class="gt_row gt_right">0.01</td>
<td headers="Course_view" class="gt_row gt_right">0.19</td>
<td headers="Ethics" class="gt_row gt_right">0.00</td>
<td headers="Feedback" class="gt_row gt_right">0.01</td>
<td headers="General" class="gt_row gt_right">0.01</td>
<td headers="Group_work" class="gt_row gt_right">0.73</td>
<td headers="Instructions" class="gt_row gt_right">0.02</td>
<td headers="La_types" class="gt_row gt_right">0.00</td>
<td headers="Practicals" class="gt_row gt_right">0.01</td>
<td headers="Social" class="gt_row gt_right">0.01</td>
<td headers="Theory" class="gt_row gt_right">0.00</td></tr>
    <tr><td headers="From\To" class="gt_row gt_left">Instructions</td>
<td headers="Applications" class="gt_row gt_right">0.00</td>
<td headers="Assignment" class="gt_row gt_right">0.02</td>
<td headers="Course_view" class="gt_row gt_right">0.33</td>
<td headers="Ethics" class="gt_row gt_right">0.00</td>
<td headers="Feedback" class="gt_row gt_right">0.03</td>
<td headers="General" class="gt_row gt_right">0.04</td>
<td headers="Group_work" class="gt_row gt_right">0.12</td>
<td headers="Instructions" class="gt_row gt_right">0.37</td>
<td headers="La_types" class="gt_row gt_right">0.02</td>
<td headers="Practicals" class="gt_row gt_right">0.03</td>
<td headers="Social" class="gt_row gt_right">0.04</td>
<td headers="Theory" class="gt_row gt_right">0.00</td></tr>
    <tr><td headers="From\To" class="gt_row gt_left">La_types</td>
<td headers="Applications" class="gt_row gt_right">0.01</td>
<td headers="Assignment" class="gt_row gt_right">0.06</td>
<td headers="Course_view" class="gt_row gt_right">0.24</td>
<td headers="Ethics" class="gt_row gt_right">0.01</td>
<td headers="Feedback" class="gt_row gt_right">0.00</td>
<td headers="General" class="gt_row gt_right">0.10</td>
<td headers="Group_work" class="gt_row gt_right">0.07</td>
<td headers="Instructions" class="gt_row gt_right">0.05</td>
<td headers="La_types" class="gt_row gt_right">0.38</td>
<td headers="Practicals" class="gt_row gt_right">0.03</td>
<td headers="Social" class="gt_row gt_right">0.01</td>
<td headers="Theory" class="gt_row gt_right">0.03</td></tr>
    <tr><td headers="From\To" class="gt_row gt_left">Practicals</td>
<td headers="Applications" class="gt_row gt_right">0.00</td>
<td headers="Assignment" class="gt_row gt_right">0.02</td>
<td headers="Course_view" class="gt_row gt_right">0.17</td>
<td headers="Ethics" class="gt_row gt_right">0.00</td>
<td headers="Feedback" class="gt_row gt_right">0.01</td>
<td headers="General" class="gt_row gt_right">0.01</td>
<td headers="Group_work" class="gt_row gt_right">0.03</td>
<td headers="Instructions" class="gt_row gt_right">0.02</td>
<td headers="La_types" class="gt_row gt_right">0.01</td>
<td headers="Practicals" class="gt_row gt_right">0.73</td>
<td headers="Social" class="gt_row gt_right">0.00</td>
<td headers="Theory" class="gt_row gt_right">0.01</td></tr>
    <tr><td headers="From\To" class="gt_row gt_left">Social</td>
<td headers="Applications" class="gt_row gt_right">0.00</td>
<td headers="Assignment" class="gt_row gt_right">0.01</td>
<td headers="Course_view" class="gt_row gt_right">0.25</td>
<td headers="Ethics" class="gt_row gt_right">0.00</td>
<td headers="Feedback" class="gt_row gt_right">0.00</td>
<td headers="General" class="gt_row gt_right">0.01</td>
<td headers="Group_work" class="gt_row gt_right">0.12</td>
<td headers="Instructions" class="gt_row gt_right">0.11</td>
<td headers="La_types" class="gt_row gt_right">0.01</td>
<td headers="Practicals" class="gt_row gt_right">0.02</td>
<td headers="Social" class="gt_row gt_right">0.48</td>
<td headers="Theory" class="gt_row gt_right">0.00</td></tr>
    <tr><td headers="From\To" class="gt_row gt_left">Theory</td>
<td headers="Applications" class="gt_row gt_right">0.00</td>
<td headers="Assignment" class="gt_row gt_right">0.02</td>
<td headers="Course_view" class="gt_row gt_right">0.15</td>
<td headers="Ethics" class="gt_row gt_right">0.03</td>
<td headers="Feedback" class="gt_row gt_right">0.00</td>
<td headers="General" class="gt_row gt_right">0.02</td>
<td headers="Group_work" class="gt_row gt_right">0.06</td>
<td headers="Instructions" class="gt_row gt_right">0.01</td>
<td headers="La_types" class="gt_row gt_right">0.05</td>
<td headers="Practicals" class="gt_row gt_right">0.05</td>
<td headers="Social" class="gt_row gt_right">0.00</td>
<td headers="Theory" class="gt_row gt_right">0.60</td></tr>
  </tbody>
  
  
</table>
</div>
</div>
</div>
</div>
<p>As we mentioned earlier, we will use a novel plotting technique that is more suitable for large process models. Below, we plot the transition probabilities with the <code>qgraph()</code> function from the <code>qgraph</code> package (<a href="#fig-overallplot1">Figure&nbsp;<span>12.13</span></a>). We use some arguments to improve the process model visualization. First, we use the argument <code>cut = 0.15</code> to show the edges with probabilities below 0.15 in lower thickness and colour intensity. This <em>cut</em> makes the graph easier to read and less crowded, and gives emphasis to the edges which matter. The argument <code>minimum = 0.05</code> hides small edges below the probability threshold of 0.05. We use <code>edge.labels = TRUE</code> to show the transition probabilities as edge labels. The argument <code>color</code> gets the colour palette from the sequence with the function <code>cpal()</code> and the argument <code>curveAll = TRUE</code> ensures the graph shows curved edges. The <code>"colorblind"</code> theme makes sure that the colours can be seen by everyone regardless of colour vision abilities. Lastly, the <code>mar</code> argument sets the margin of the figure to make all graphical aspects fit within the figure area.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb68"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a>Labelx <span class="ot">&lt;-</span> <span class="fu">alphabet</span>(seq_data_all) <span class="co"># get the labels to use them as nodes names.</span></span>
<span id="cb68-2"><a href="#cb68-2" aria-hidden="true" tabindex="-1"></a>transitionsplot <span class="ot">&lt;-</span> <span class="fu">qgraph</span>(</span>
<span id="cb68-3"><a href="#cb68-3" aria-hidden="true" tabindex="-1"></a>  overalltransitions, <span class="at">cut =</span> <span class="fl">0.15</span>, <span class="at">minimum =</span> <span class="fl">0.05</span>, </span>
<span id="cb68-4"><a href="#cb68-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">labels =</span> Labelx, <span class="at">edge.labels =</span> <span class="cn">TRUE</span>, <span class="at">edge.label.cex =</span> <span class="fl">0.65</span>, </span>
<span id="cb68-5"><a href="#cb68-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">color =</span> <span class="fu">cpal</span>(seq_data_all), <span class="at">curveAll =</span> <span class="cn">TRUE</span>, </span>
<span id="cb68-6"><a href="#cb68-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">theme =</span> <span class="st">"colorblind"</span>, <span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">4</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">3</span>)</span>
<span id="cb68-7"><a href="#cb68-7" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-overallplot1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="ch12-markov_files/figure-html/fig-overallplot1-1.png" class="img-fluid figure-img" width="1800"></p>
<p></p><figcaption class="figure-caption"><strong>Figure</strong>&nbsp;13<strong>.</strong> Process map for the overall process.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>The <code>seqtrate()</code> function only computes the transition probabilities but does not compute the initial probabilities. While it is not difficult to calculate the proportions of starting in each state, we can also estimate a simple Markov model which does the same with a short command. We do so using the <code>build_mm()</code> function as per Section <span class="math inline">\(\ref{markov}\)</span>, recalling that the <code>build_mm()</code> function is distinct from <code>build_hmm()</code>, <code>build_mmm()</code>, and <code>build_mhmm()</code> in that it is the only build function that automatically estimates the parameters of the model.</p>
<p>The plotting now includes an extra option called <code>pie = overallmodel$initial_probs</code> which tells <code>qgraph</code> to use the initial probabilities from the fitted MM as the sizes of the pie charts in the borders of the nodes in <a href="#fig-overallplot2">Figure&nbsp;<span>12.14</span></a>. For instance, the pie around <em>Course view</em> is around half of the circle corresponding to 0.48 initial probability to start from <em>Course view</em>. Please also note that the graph is otherwise equal to the one generated via <code>seqtrate()</code> apart from these initial probabilities.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb69"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a>overallmodel <span class="ot">&lt;-</span> <span class="fu">build_mm</span>(seq_data_all)</span>
<span id="cb69-2"><a href="#cb69-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-3"><a href="#cb69-3" aria-hidden="true" tabindex="-1"></a>overallplot <span class="ot">&lt;-</span> <span class="fu">qgraph</span>(</span>
<span id="cb69-4"><a href="#cb69-4" aria-hidden="true" tabindex="-1"></a>  overalltransitions, </span>
<span id="cb69-5"><a href="#cb69-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">cut =</span> <span class="fl">0.15</span>, </span>
<span id="cb69-6"><a href="#cb69-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">minimum =</span> <span class="fl">0.05</span>, </span>
<span id="cb69-7"><a href="#cb69-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">labels =</span> Labelx, </span>
<span id="cb69-8"><a href="#cb69-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">4</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">3</span>), </span>
<span id="cb69-9"><a href="#cb69-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">edge.labels =</span> <span class="cn">TRUE</span>, </span>
<span id="cb69-10"><a href="#cb69-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">edge.label.cex =</span> <span class="fl">0.65</span>, </span>
<span id="cb69-11"><a href="#cb69-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">color =</span> <span class="fu">cpal</span>(seq_data_all), </span>
<span id="cb69-12"><a href="#cb69-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">curveAll =</span> <span class="cn">TRUE</span>, </span>
<span id="cb69-13"><a href="#cb69-13" aria-hidden="true" tabindex="-1"></a>  <span class="at">theme =</span> <span class="st">"colorblind"</span>, </span>
<span id="cb69-14"><a href="#cb69-14" aria-hidden="true" tabindex="-1"></a>  <span class="at">pie =</span> overallmodel<span class="sc">$</span>initial_probs</span>
<span id="cb69-15"><a href="#cb69-15" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-overallplot2" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="ch12-markov_files/figure-html/fig-overallplot2-1.png" class="img-fluid figure-img" width="1800"></p>
<p></p><figcaption class="figure-caption"><strong>Figure</strong>&nbsp;14<strong>.</strong> Process map for the overall process with initial probabilities.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>Having plotted the transitions of the full dataset, we can now look for transition patterns, that is typical transition patterns (i.e., clusters) that are repeated within the data. The procedure is the same as before. In the next example, we use the function <code>build_mmm()</code> to build the model with four clusters as a demonstration. Ideally, researchers need to estimate several models and choose the best model based on model selection criteria (such as BIC) values as well as interpretability.</p>
<p>The steps involved in fitting the model are as before; we make use of the function <code>fit_model()</code> to estimate the model. The results of the running the code will be an MM for each cluster (with distinct initial and transition probabilities). Given the number of sequences in the dataset, their length, and the number of states, the computational burden is larger than for previous applications in this chapter. For illustrative purposes, instead of repeated EM runs with random starting values, we use single EM run followed by global optimisation, using the argument <code>global_step = TRUE</code>. One benefit of this global (and local) step in <code>fit_model</code> over the EM algorithm is the flexibility to define a maximum runtime (in seconds) for the optimization process (argument <code>maxtime</code> in <code>control_global</code>). This can be valuable for larger problems with predefined runtime (e.g., in a shared computer cluster). Note, however, that relying on the runtime can lead to non-reproducible results even with fixed seed if the optimisation terminates due to the time limit. Finally, we run additional local optimisation step using the results of the global optimisation, for more accurate results. The last argument <code>threads = 16</code> instructs to use parallel computing to enable faster fitting (please, customise according to the number of cores in your computer). As for the starting values, we use the transition probabilities computed from the full data for all clusters, and random values for the initial probabilities.</p>
<p>While in theory many of global optimisation algorithms should eventually find the global optimum, in practice there are no guarantees that it is found in limited time. Thus, as earlier, in practice it is advisable to try different global/local optimisation algorithms and/or EM algorithm with different initial values to make it more likely that the global optimum is found (see <span class="citation" data-cites="Helske2019">[<a href="#ref-Helske2019" role="doc-biblioref">4</a>]</span> for further discussion).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb70-2"><a href="#cb70-2" aria-hidden="true" tabindex="-1"></a>trans_probs <span class="ot">&lt;-</span> <span class="fu">simulate_transition_probs</span>(<span class="dv">12</span>, <span class="dv">4</span>, <span class="at">diag_c =</span> <span class="dv">5</span>)</span>
<span id="cb70-3"><a href="#cb70-3" aria-hidden="true" tabindex="-1"></a>init_probs <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">prop.table</span>(<span class="fu">table</span>(seq_data_all[,<span class="dv">1</span>])[<span class="dv">1</span><span class="sc">:</span><span class="dv">12</span>]))</span>
<span id="cb70-4"><a href="#cb70-4" aria-hidden="true" tabindex="-1"></a>init_probs <span class="ot">&lt;-</span> <span class="fu">replicate</span>(<span class="dv">4</span>, init_probs, <span class="at">simplify =</span> <span class="cn">FALSE</span>)</span>
<span id="cb70-5"><a href="#cb70-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-6"><a href="#cb70-6" aria-hidden="true" tabindex="-1"></a>builtseqLMS <span class="ot">&lt;-</span> <span class="fu">build_mmm</span>(</span>
<span id="cb70-7"><a href="#cb70-7" aria-hidden="true" tabindex="-1"></a>  seq_data_all,</span>
<span id="cb70-8"><a href="#cb70-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">transition_probs =</span> trans_probs,</span>
<span id="cb70-9"><a href="#cb70-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">initial_probs =</span> init_probs</span>
<span id="cb70-10"><a href="#cb70-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb70-11"><a href="#cb70-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-12"><a href="#cb70-12" aria-hidden="true" tabindex="-1"></a>fitLMS <span class="ot">&lt;-</span> <span class="fu">fit_model</span>(</span>
<span id="cb70-13"><a href="#cb70-13" aria-hidden="true" tabindex="-1"></a>  builtseqLMS, </span>
<span id="cb70-14"><a href="#cb70-14" aria-hidden="true" tabindex="-1"></a>  <span class="at">global_step =</span> <span class="cn">TRUE</span>,</span>
<span id="cb70-15"><a href="#cb70-15" aria-hidden="true" tabindex="-1"></a>  <span class="at">control_global =</span> <span class="fu">list</span>(</span>
<span id="cb70-16"><a href="#cb70-16" aria-hidden="true" tabindex="-1"></a>    <span class="at">maxtime =</span> <span class="dv">3600</span>, </span>
<span id="cb70-17"><a href="#cb70-17" aria-hidden="true" tabindex="-1"></a>    <span class="at">maxeval =</span> <span class="fl">1e5</span>,</span>
<span id="cb70-18"><a href="#cb70-18" aria-hidden="true" tabindex="-1"></a>    <span class="at">algorithm =</span> <span class="st">"NLOPT_GD_STOGO_RAND"</span>),</span>
<span id="cb70-19"><a href="#cb70-19" aria-hidden="true" tabindex="-1"></a>  <span class="at">local_step =</span> <span class="cn">TRUE</span>,</span>
<span id="cb70-20"><a href="#cb70-20" aria-hidden="true" tabindex="-1"></a>  <span class="at">threads =</span> <span class="dv">16</span></span>
<span id="cb70-21"><a href="#cb70-21" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb70-22"><a href="#cb70-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-23"><a href="#cb70-23" aria-hidden="true" tabindex="-1"></a>fitLMS<span class="sc">$</span>global_results<span class="sc">$</span>message</span>
<span id="cb70-24"><a href="#cb70-24" aria-hidden="true" tabindex="-1"></a>fitLMS<span class="sc">$</span>logLik</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-hash="ch12-markov_cache/html/unnamed-chunk-45_cd1c9584337acf4d60ae9d08b449adbb">

</div>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>[1] "NLOPT_SUCCESS: Generic success return value."</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] -114491.2</code></pre>
</div>
</div>
<p>Before plotting the clusters, let us do some cleanups. First, we get the transition probabilities of each cluster and assign them to a variable. In that way, it is easier to manipulate and work with. In the same way, we can extract the initial probabilities for each cluster.</p>
<div class="cell" data-hash="ch12-markov_cache/html/unnamed-chunk-47_623e15e3e890c5ad6be727892e4b198c">
<div class="sourceCode cell-code" id="cb73"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a><span class="do">##extract transition probabilities of each cluster</span></span>
<span id="cb73-2"><a href="#cb73-2" aria-hidden="true" tabindex="-1"></a>Clustertp1 <span class="ot">&lt;-</span> fitLMS<span class="sc">$</span>model<span class="sc">$</span>transition_probs<span class="sc">$</span><span class="st">`</span><span class="at">Cluster 1</span><span class="st">`</span></span>
<span id="cb73-3"><a href="#cb73-3" aria-hidden="true" tabindex="-1"></a>Clustertp2 <span class="ot">&lt;-</span> fitLMS<span class="sc">$</span>model<span class="sc">$</span>transition_probs<span class="sc">$</span><span class="st">`</span><span class="at">Cluster 2</span><span class="st">`</span></span>
<span id="cb73-4"><a href="#cb73-4" aria-hidden="true" tabindex="-1"></a>Clustertp3 <span class="ot">&lt;-</span> fitLMS<span class="sc">$</span>model<span class="sc">$</span>transition_probs<span class="sc">$</span><span class="st">`</span><span class="at">Cluster 3</span><span class="st">`</span></span>
<span id="cb73-5"><a href="#cb73-5" aria-hidden="true" tabindex="-1"></a>Clustertp4 <span class="ot">&lt;-</span> fitLMS<span class="sc">$</span>model<span class="sc">$</span>transition_probs<span class="sc">$</span><span class="st">`</span><span class="at">Cluster 4</span><span class="st">`</span></span>
<span id="cb73-6"><a href="#cb73-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-7"><a href="#cb73-7" aria-hidden="true" tabindex="-1"></a><span class="do">##extract initial probabilities of each cluster</span></span>
<span id="cb73-8"><a href="#cb73-8" aria-hidden="true" tabindex="-1"></a>Clusterinitp1 <span class="ot">&lt;-</span> fitLMS<span class="sc">$</span>model<span class="sc">$</span>initial_probs<span class="sc">$</span><span class="st">`</span><span class="at">Cluster 1</span><span class="st">`</span></span>
<span id="cb73-9"><a href="#cb73-9" aria-hidden="true" tabindex="-1"></a>Clusterinitp2 <span class="ot">&lt;-</span> fitLMS<span class="sc">$</span>model<span class="sc">$</span>initial_probs<span class="sc">$</span><span class="st">`</span><span class="at">Cluster 2</span><span class="st">`</span></span>
<span id="cb73-10"><a href="#cb73-10" aria-hidden="true" tabindex="-1"></a>Clusterinitp3 <span class="ot">&lt;-</span> fitLMS<span class="sc">$</span>model<span class="sc">$</span>initial_probs<span class="sc">$</span><span class="st">`</span><span class="at">Cluster 3</span><span class="st">`</span></span>
<span id="cb73-11"><a href="#cb73-11" aria-hidden="true" tabindex="-1"></a>Clusterinitp4 <span class="ot">&lt;-</span> fitLMS<span class="sc">$</span>model<span class="sc">$</span>initial_probs<span class="sc">$</span><span class="st">`</span><span class="at">Cluster 4</span><span class="st">`</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Plotting the process maps can be performed in the same way we did before. However, if we need to compare clusters, it is best if we use a unified layout. An average layout can be computed with the function <code>averageLayout()</code> which takes the transition probabilities of the four clusters as input and creates — as the name implies— an averaged layout. Another option is to use the same layout of the <code>overallplot</code> in the previous example. This can be obtained from the plot object <code>overallplot$layout</code>. This can be helpful if you would like to plot the four plots corresponding to each cluster with the same layout as the overall plot (see <a href="#fig-plotclusters">Figure&nbsp;<span>12.15</span></a>).</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb74"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a>Labelx <span class="ot">&lt;-</span> <span class="fu">colnames</span>(Clustertp1) <span class="co"># we need to get the labels</span></span>
<span id="cb74-2"><a href="#cb74-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-3"><a href="#cb74-3" aria-hidden="true" tabindex="-1"></a>Averagelayout <span class="ot">&lt;-</span> <span class="fu">averageLayout</span>(</span>
<span id="cb74-4"><a href="#cb74-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">list</span>(Clustertp1, Clustertp2, Clustertp3, Clustertp4)</span>
<span id="cb74-5"><a href="#cb74-5" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb74-6"><a href="#cb74-6" aria-hidden="true" tabindex="-1"></a><span class="do">## You can also try with this layout from the previous plot</span></span>
<span id="cb74-7"><a href="#cb74-7" aria-hidden="true" tabindex="-1"></a>Overalllayout <span class="ot">&lt;-</span> overallplot<span class="sc">$</span>layout </span>
<span id="cb74-8"><a href="#cb74-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-9"><a href="#cb74-9" aria-hidden="true" tabindex="-1"></a><span class="fu">qgraph</span>(</span>
<span id="cb74-10"><a href="#cb74-10" aria-hidden="true" tabindex="-1"></a>  Clustertp1, <span class="at">cut =</span> <span class="fl">0.15</span>, <span class="at">minimum =</span> <span class="fl">0.05</span> , <span class="at">labels =</span> Labelx,</span>
<span id="cb74-11"><a href="#cb74-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">edge.labels =</span> <span class="cn">TRUE</span>, <span class="at">edge.label.cex =</span> <span class="fl">0.65</span>, <span class="at">color =</span> <span class="fu">cpal</span>(seq_data_all), </span>
<span id="cb74-12"><a href="#cb74-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">layout =</span> Averagelayout, <span class="at">pie =</span> Clusterinitp1, <span class="at">curveAll =</span> <span class="cn">TRUE</span>, </span>
<span id="cb74-13"><a href="#cb74-13" aria-hidden="true" tabindex="-1"></a>  <span class="at">theme =</span> <span class="st">"colorblind"</span>, <span class="at">title =</span> <span class="st">"Diverse"</span></span>
<span id="cb74-14"><a href="#cb74-14" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb74-15"><a href="#cb74-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-16"><a href="#cb74-16" aria-hidden="true" tabindex="-1"></a><span class="fu">qgraph</span>(</span>
<span id="cb74-17"><a href="#cb74-17" aria-hidden="true" tabindex="-1"></a>  Clustertp2, <span class="at">cut =</span> <span class="fl">0.15</span>, <span class="at">minimum =</span> <span class="fl">0.05</span>, <span class="at">labels =</span> Labelx,</span>
<span id="cb74-18"><a href="#cb74-18" aria-hidden="true" tabindex="-1"></a>  <span class="at">edge.labels =</span> <span class="cn">TRUE</span>, <span class="at">edge.label.cex =</span> <span class="fl">0.65</span>, <span class="at">color =</span> <span class="fu">cpal</span>(seq_data_all),  </span>
<span id="cb74-19"><a href="#cb74-19" aria-hidden="true" tabindex="-1"></a>  <span class="at">layout =</span> Averagelayout, <span class="at">pie =</span> Clusterinitp2, <span class="at">curveAll =</span> <span class="cn">TRUE</span>, </span>
<span id="cb74-20"><a href="#cb74-20" aria-hidden="true" tabindex="-1"></a>  <span class="at">theme =</span> <span class="st">"colorblind"</span>, <span class="at">title =</span> <span class="st">"Assignment-oriented"</span></span>
<span id="cb74-21"><a href="#cb74-21" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb74-22"><a href="#cb74-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-23"><a href="#cb74-23" aria-hidden="true" tabindex="-1"></a><span class="fu">qgraph</span>(</span>
<span id="cb74-24"><a href="#cb74-24" aria-hidden="true" tabindex="-1"></a>  Clustertp3, <span class="at">cut =</span> <span class="fl">0.15</span>, <span class="at">minimum =</span> <span class="fl">0.05</span>, <span class="at">labels =</span> Labelx,</span>
<span id="cb74-25"><a href="#cb74-25" aria-hidden="true" tabindex="-1"></a>  <span class="at">edge.labels =</span> <span class="cn">TRUE</span>, <span class="at">edge.label.cex =</span> <span class="fl">0.65</span>, <span class="at">color =</span> <span class="fu">cpal</span>(seq_data_all),  </span>
<span id="cb74-26"><a href="#cb74-26" aria-hidden="true" tabindex="-1"></a>  <span class="at">layout =</span> Averagelayout, <span class="at">pie =</span> Clusterinitp3, <span class="at">curveAll =</span> <span class="cn">TRUE</span>, </span>
<span id="cb74-27"><a href="#cb74-27" aria-hidden="true" tabindex="-1"></a>  <span class="at">theme =</span> <span class="st">"colorblind"</span>, <span class="at">title =</span> <span class="st">"Practical-oriented"</span></span>
<span id="cb74-28"><a href="#cb74-28" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb74-29"><a href="#cb74-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-30"><a href="#cb74-30" aria-hidden="true" tabindex="-1"></a><span class="fu">qgraph</span>(</span>
<span id="cb74-31"><a href="#cb74-31" aria-hidden="true" tabindex="-1"></a>  Clustertp4, <span class="at">cut =</span> <span class="fl">0.15</span>, <span class="at">minimum =</span> <span class="fl">0.05</span> , <span class="at">labels =</span> Labelx, </span>
<span id="cb74-32"><a href="#cb74-32" aria-hidden="true" tabindex="-1"></a>  <span class="at">edge.labels =</span> <span class="cn">TRUE</span>, <span class="at">edge.label.cex =</span> <span class="fl">0.65</span>, <span class="at">color =</span> <span class="fu">cpal</span>(seq_data_all),  </span>
<span id="cb74-33"><a href="#cb74-33" aria-hidden="true" tabindex="-1"></a>  <span class="at">layout =</span> Averagelayout, <span class="at">pie =</span> Clusterinitp4, <span class="at">curveAll =</span> <span class="cn">TRUE</span>, </span>
<span id="cb74-34"><a href="#cb74-34" aria-hidden="true" tabindex="-1"></a>  <span class="at">theme =</span> <span class="st">"colorblind"</span>, <span class="at">title =</span> <span class="st">"Group-centered"</span></span>
<span id="cb74-35"><a href="#cb74-35" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-plotclusters" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="ch12-markov_files/figure-html/fig-plotclusters-1.png" class="img-fluid figure-img" width="1800"></p>
<p></p><figcaption class="figure-caption"><strong>Figure</strong>&nbsp;15<strong>.</strong> Process maps for each cluster.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>Oftentimes, the researcher is interested in comparing two pre-defined fixed groups, e.g., high achievers and low achievers, rather than between the computed clusters. In the next example we will compare high to low achievers based on their achievement levels. First, we have to create a separate sequence object for each group. We do this by filtering but you can do it in other ways. For instance, you can create two sequences from scratch for each group. The next is to build the MMs separately for each group.</p>
<div class="cell" data-hash="ch12-markov_cache/html/unnamed-chunk-49_a25b7f55f29964c8c295a70b3b65c822">
<div class="sourceCode cell-code" id="cb75"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a>seq_high <span class="ot">&lt;-</span> seq_data_all[seq_data<span class="sc">$</span>Achievementlevel4 <span class="sc">&lt;=</span> <span class="dv">2</span>,]</span>
<span id="cb75-2"><a href="#cb75-2" aria-hidden="true" tabindex="-1"></a>seq_low <span class="ot">&lt;-</span>  seq_data_all[seq_data<span class="sc">$</span>Achievementlevel4 <span class="sc">&gt;</span> <span class="dv">2</span>,]</span>
<span id="cb75-3"><a href="#cb75-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-4"><a href="#cb75-4" aria-hidden="true" tabindex="-1"></a>high_mm <span class="ot">&lt;-</span> <span class="fu">build_mm</span>(seq_high)</span>
<span id="cb75-5"><a href="#cb75-5" aria-hidden="true" tabindex="-1"></a>low_mm <span class="ot">&lt;-</span> <span class="fu">build_mm</span>(seq_low)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Before plotting the groups, let us do some cleaning, like we did before. First, we get the transition and initial probabilities of each group. We also compute an average layout. Please note that you can use the layout from the previous examples if you are comparing the models against each other and you need a unified framework. The plotting is the same as before (see <a href="#fig-hilow">Figure&nbsp;<span>12.16</span></a>).</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb76"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb76-2"><a href="#cb76-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-3"><a href="#cb76-3" aria-hidden="true" tabindex="-1"></a><span class="do">##extract transition probabilities of each cluster</span></span>
<span id="cb76-4"><a href="#cb76-4" aria-hidden="true" tabindex="-1"></a>Highprobs <span class="ot">&lt;-</span> high_mm<span class="sc">$</span>transition_probs</span>
<span id="cb76-5"><a href="#cb76-5" aria-hidden="true" tabindex="-1"></a>Lowprobs <span class="ot">&lt;-</span> low_mm<span class="sc">$</span>transition_probs</span>
<span id="cb76-6"><a href="#cb76-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-7"><a href="#cb76-7" aria-hidden="true" tabindex="-1"></a><span class="do">##extract initial probabilities of each cluster</span></span>
<span id="cb76-8"><a href="#cb76-8" aria-hidden="true" tabindex="-1"></a>Highinit <span class="ot">&lt;-</span> high_mm<span class="sc">$</span>initial_probs</span>
<span id="cb76-9"><a href="#cb76-9" aria-hidden="true" tabindex="-1"></a>Lowinit <span class="ot">&lt;-</span> high_mm<span class="sc">$</span>initial_probs</span>
<span id="cb76-10"><a href="#cb76-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-11"><a href="#cb76-11" aria-hidden="true" tabindex="-1"></a>Averagelayout <span class="ot">&lt;-</span> <span class="fu">averageLayout</span>(<span class="fu">list</span>(Highprobs, Lowprobs))</span>
<span id="cb76-12"><a href="#cb76-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-13"><a href="#cb76-13" aria-hidden="true" tabindex="-1"></a>Highplot <span class="ot">&lt;-</span> <span class="fu">qgraph</span>(</span>
<span id="cb76-14"><a href="#cb76-14" aria-hidden="true" tabindex="-1"></a>  Highprobs, <span class="at">cut =</span> <span class="fl">0.15</span>, <span class="at">minimum =</span> <span class="fl">0.05</span>, <span class="at">labels =</span> Labelx,</span>
<span id="cb76-15"><a href="#cb76-15" aria-hidden="true" tabindex="-1"></a>  <span class="at">edge.labels =</span> <span class="cn">TRUE</span>, <span class="at">edge.label.cex =</span> <span class="fl">0.65</span>, </span>
<span id="cb76-16"><a href="#cb76-16" aria-hidden="true" tabindex="-1"></a>  <span class="at">color =</span> <span class="fu">cpal</span>(seq_data_all), <span class="at">layout =</span> Averagelayout, </span>
<span id="cb76-17"><a href="#cb76-17" aria-hidden="true" tabindex="-1"></a>  <span class="at">pie =</span> Highinit, <span class="at">theme =</span> <span class="st">"colorblind"</span>, <span class="at">title =</span> <span class="st">"High achievers"</span></span>
<span id="cb76-18"><a href="#cb76-18" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb76-19"><a href="#cb76-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-20"><a href="#cb76-20" aria-hidden="true" tabindex="-1"></a>Lowplot <span class="ot">&lt;-</span>  <span class="fu">qgraph</span>(</span>
<span id="cb76-21"><a href="#cb76-21" aria-hidden="true" tabindex="-1"></a>  Lowprobs, <span class="at">cut=</span><span class="fl">0.15</span>, <span class="at">minimum =</span> <span class="fl">0.05</span>, <span class="at">labels =</span> Labelx,</span>
<span id="cb76-22"><a href="#cb76-22" aria-hidden="true" tabindex="-1"></a>  <span class="at">edge.labels =</span> <span class="cn">TRUE</span>, <span class="at">edge.label.cex =</span> <span class="fl">0.65</span>, </span>
<span id="cb76-23"><a href="#cb76-23" aria-hidden="true" tabindex="-1"></a>  <span class="at">color =</span> <span class="fu">cpal</span>(seq_data_all), <span class="at">layout =</span> Averagelayout, </span>
<span id="cb76-24"><a href="#cb76-24" aria-hidden="true" tabindex="-1"></a>  <span class="at">pie =</span> Lowinit, <span class="at">theme =</span> <span class="st">"colorblind"</span>, <span class="at">title =</span> <span class="st">"Low achievers"</span></span>
<span id="cb76-25"><a href="#cb76-25" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-hilow" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="ch12-markov_files/figure-html/fig-hilow-1.png" class="img-fluid figure-img" width="1800"></p>
<p></p><figcaption class="figure-caption"><strong>Figure</strong>&nbsp;16<strong>.</strong> Process maps for high achievers and low achievers using average layout.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>We can also plot the difference plot (see <a href="#fig-diff">Figure&nbsp;<span>12.17</span></a>); that is, what the low achievers do less than high achievers. In this case, red edges are negative (events they do less) and blue edges are positive (events that they do more than high achievers). As you can see, the differences are not that huge. In fact, much of the literature comparing high and low achievers uses higher thresholds e.g., top 25% to bottom 25% or even top 10% to bottom 10%.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb77"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a>diffplot <span class="ot">&lt;-</span> <span class="fu">qgraph</span>(</span>
<span id="cb77-2"><a href="#cb77-2" aria-hidden="true" tabindex="-1"></a>  Lowprobs <span class="sc">-</span> Highprobs, <span class="at">cut =</span> <span class="fl">0.15</span>, <span class="at">minimum =</span> <span class="fl">0.05</span>, <span class="at">labels =</span> Labelx,</span>
<span id="cb77-3"><a href="#cb77-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">edge.labels =</span> <span class="cn">TRUE</span>, <span class="at">edge.label.cex =</span> <span class="fl">0.65</span>, <span class="at">layout =</span> Averagelayout, </span>
<span id="cb77-4"><a href="#cb77-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">color =</span> <span class="fu">cpal</span>(seq_data_all), <span class="at">theme =</span> <span class="st">"colorblind"</span></span>
<span id="cb77-5"><a href="#cb77-5" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-diff" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="ch12-markov_files/figure-html/fig-diff-1.png" class="img-fluid figure-img" width="2100"></p>
<p></p><figcaption class="figure-caption"><strong>Figure</strong>&nbsp;17<strong>.</strong> Difference between process maps of high achievers and low achievers using average layout.</figcaption><p></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="conclusions-further-readings" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="conclusions-further-readings"><span class="header-section-number">5</span> Conclusions &amp; further readings</h2>
<p>Markovian models provide a flexible model-based approach for analysing complex sequence data. MMs and HMMs have proven useful in many application areas such as biology and speech recognition, and can be a valuable tool in analysing data in educational settings as well. Their mixture variants allow for the representation of complex systems by combining multiple MMs or HMMs, each capturing different aspects of the underlying processes, allowing probabilistic clustering, information compression (e.g.&nbsp;visualisation of multicategory data from multiple domains), and detection of latent features of sequence data (e.g, extraction of different learning strategies). The ability to incorporate covariates in the case of MMMs and MHMMs makes those models even more powerful, and generally MMs and MMMs represent useful tools in the field of process mining also.</p>
<p>The <code>seqHMM</code> package used in the examples supports time-constant covariates for predicting cluster memberships for each individual. In theory, covariates could be used to define transition or emission probabilities as well, leading to subject-specific and possibly time-varying transition and emission probabilities (in the case of time-varying covariates). However, at the time of writing this chapter, these are not supported in <code>seqHMM</code> (this may change in the future). In R, there are at least two other, potentially useful packages: for MMs, the <code>dynamite</code> <span class="citation" data-cites="dynamitepaper">[<a href="#ref-dynamitepaper" role="doc-biblioref">41</a>]</span> package supports covariates on the transition probabilities with potentially time-varying effects, whereas <code>LMest</code> <span class="citation" data-cites="LMest">[<a href="#ref-LMest" role="doc-biblioref">42</a>]</span> supports MMs and HMMs with covariates, and restricted variants of the MHMM where only the initial and transition matrices vary between clusters. Going beyond the R software, some commercial software also offers tools to analyse Markovian models, including latentGold <span class="citation" data-cites="latentgold">[<a href="#ref-latentgold" role="doc-biblioref">43</a>]</span> and Mplus <span class="citation" data-cites="mplus">[<a href="#ref-mplus" role="doc-biblioref">11</a>]</span>.</p>
<p>The conditional independence assumption of observations given the latent states in HMMs can sometimes be unrealistic. In these settings, the so-called double chain MMs can be used <span class="citation" data-cites="Berchtold">[<a href="#ref-Berchtold" role="doc-biblioref">44</a>]</span>. There the current observation is allowed to depend on both the current state and the previous observation. Some restricted variants of such models are implemented in the <code>march</code> package in R <span class="citation" data-cites="march">[<a href="#ref-march" role="doc-biblioref">45</a>]</span>. Finally, variable-order MMs extend basic MMs by allowing the order of the MM to vary in time. A <code>TraMineR</code>-compatible implementation of variable-order models can be found in the <code>PST</code> package <span class="citation" data-cites="Gabadinho2016">[<a href="#ref-Gabadinho2016" role="doc-biblioref">46</a>]</span>.</p>
<p>We encourage readers to read more about how to interpret the results in the original study where the data for this chapter was drawn from <span class="citation" data-cites="SAQR2022104581">[<a href="#ref-SAQR2022104581" role="doc-biblioref">36</a>]</span>. We also encourage readers to learn more about Markovian models in the context of multi-channel sequence analysis in Chapter 13 <span class="citation" data-cites="Lopez-Pernas2024-kf">[<a href="#ref-Lopez-Pernas2024-kf" role="doc-biblioref">8</a>]</span>.</p>
</section>
<section id="acknowledgements" class="level2" data-number="6">
<h2 data-number="6" class="anchored" data-anchor-id="acknowledgements"><span class="header-section-number">6</span> Acknowledgements</h2>
<p>JH and SH were supported by Research Council of Finland (PREDLIFE: Towards well-informed decisions: Predicting long-term effects of policy reforms on life trajectories, grants 331817 and 331816). MS was supported by Research Council of Finland (TOPEILA: Towards precision education: Idiographic learning analytics, grant 350560).</p>


</section>
<section id="bibliography" class="level1 unnumbered">
<h1 class="unnumbered">References</h1>
<div id="refs" class="references csl-bib-body" role="doc-bibliography">
<div id="ref-Saqr2024-tv" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">1. </div><div class="csl-right-inline">Saqr M, López-Pernas S, Helske S, Durand M, Murphy K, Studer M, Ritschard G (2024) Sequence analysis in education: Principles, technique, and tutorial with r. In: Saqr M, López-Pernas S (eds) Learning analytics methods and tutorials: A practical guide using <span>R</span>. Springer</div>
</div>
<div id="ref-LopezPernas2024" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">2. </div><div class="csl-right-inline">López-Pernas S, Saqr M (2024) Modeling the dynamics of longitudinal processes in education. A tutorial with r for the VaSSTra method. In: Saqr M, López-Pernas S (eds) Learning analytics methods and tutorials: A practical guide using <span>R</span>. Springer, pp in–press</div>
</div>
<div id="ref-Liao2022" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">3. </div><div class="csl-right-inline">Liao TF, Bolano D, Brzinsky-Fay C, Cornwell B, Fasang AE, Helske S, Piccarreta R, Raab M, Ritschard G, Struffolino E, Studer M (2022) Sequence analysis: Its past, present, and future. Social Science Research 107:102772. https://doi.org/<a href="https://doi.org/10.1016/j.ssresearch.2022.102772">10.1016/j.ssresearch.2022.102772</a></div>
</div>
<div id="ref-Helske2019" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">4. </div><div class="csl-right-inline">Helske S, Helske J (2019) Mixture hidden <span>M</span>arkov models for sequence data: The <span class="nocase">seqHMM</span> package in <span>R</span>. Journal of Statistical Software 88: https://doi.org/<a href="https://doi.org/10.18637/jss.v088.i03">10.18637/jss.v088.i03</a></div>
</div>
<div id="ref-schwarz1978" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">5. </div><div class="csl-right-inline">Schwarz GE (1978) Estimating the dimension of a model. The Annals of Statistics 6:461–464. https://doi.org/<a href="https://doi.org/10.1214/aos/1176344136">10.1214/aos/1176344136</a></div>
</div>
<div id="ref-vandePol1990" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">6. </div><div class="csl-right-inline">Pol F van de, Langeheine R (1990) Mixed <span>M</span>arkov latent class models. Sociological Methodology 20:213. https://doi.org/<a href="https://doi.org/10.2307/271087">10.2307/271087</a></div>
</div>
<div id="ref-Vermunt" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">7. </div><div class="csl-right-inline">Vermunt JK, Tran B, Magidson J (2008) Latent class models in longitudinal research. In: Menard S (ed) Handbook of longitudinal research. Elsevier, Netherlands, pp 373–385</div>
</div>
<div id="ref-Lopez-Pernas2024-kf" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">8. </div><div class="csl-right-inline">López-Pernas S, Murphy K, Saqr M (2024) Multichannel sequence analysis in educational research using r. In: Saqr M, López-Pernas S (eds) Learning analytics methods and tutorials: A practical guide using <span>R</span>. Springer, pp in–press</div>
</div>
<div id="ref-Rabiner1989" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">9. </div><div class="csl-right-inline">Rabiner L (1989) A tutorial on hidden <span>M</span>arkov models and selected applications in speech recognition. Proceedings of the IEEE 77:257–286. https://doi.org/<a href="https://doi.org/10.1109/5.18626">10.1109/5.18626</a></div>
</div>
<div id="ref-Helske2018" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">10. </div><div class="csl-right-inline">Helske S, Helske J, Eerola M (2018) <a href="https://doi.org/10.1007/978-3-319-95420-2\_11">Combining sequence analysis and hidden markov models in the analysis of complex life sequence data</a>. In: Ritschard G, Studer M (eds) Sequence analysis and related approaches: Innovative methods and applications. Springer International Publishing, Cham, pp 185–200</div>
</div>
<div id="ref-mplus" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">11. </div><div class="csl-right-inline">Muthén LK, O. MB (2017) <span class="nocase">Mplus User’s Guide</span>, 8th edition. Muthén &amp; Muthén, Los Angeles, CA, U.S.A.</div>
</div>
<div id="ref-Muthen" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">12. </div><div class="csl-right-inline">Muthén B, Muthén L <a href="https://www.statmodel.com/download/Mplus-A\%20General\%20Latent\%20Variable\%20Modeling\%20Program.pdf">Mplus: A general latent variable modeling program</a></div>
</div>
<div id="ref-Tormanen2022-ux" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">13. </div><div class="csl-right-inline">Törmänen, Järvenoja, Saqr, Malmberg, others (2022) A person-centered approach to study students’ socio-emotional interaction profiles and regulation of collaborative learning. Frontiers in Education</div>
</div>
<div id="ref-Tormanen2023-gz" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">14. </div><div class="csl-right-inline">Törmänen T, Järvenoja H, Saqr M, Malmberg J, Järvelä S (2023) Affective states and regulation of learning during socio-emotional interactions in secondary school collaborative groups. British Journal of Educational Psychology 93 Suppl 1:48–70. https://doi.org/<a href="https://doi.org/10.1111/bjep.12525">10.1111/bjep.12525</a></div>
</div>
<div id="ref-Fincham2019-yz" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">15. </div><div class="csl-right-inline">Fincham E, Gašević D, Jovanović J, Pardo A (2019) From study tactics to learning strategies: An analytical method for extracting interpretable representations. IEEE Transactions on Learning Technologies 12:59–72. https://doi.org/<a href="https://doi.org/10.1109/TLT.2018.2823317">10.1109/TLT.2018.2823317</a></div>
</div>
<div id="ref-Roles" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">16. </div><div class="csl-right-inline">Saqr M, López-Pernas S (2022) How <span>CSCL</span> roles emerge, persist, transition, and evolve over time: A four-year longitudinal study. Computers &amp; Education 189:104581</div>
</div>
<div id="ref-IHE" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">17. </div><div class="csl-right-inline">Saqr M, López-Pernas S, Jovanović J, Gašević D (2023) Intense, turbulent, or wallowing in the mire: A longitudinal study of cross-course online tactics, strategies, and trajectories. The Internet and Higher Education 57:100902</div>
</div>
<div id="ref-BOUGUETTAYA20152785" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">18. </div><div class="csl-right-inline">Bouguettaya A, Yu Q, Liu X, Zhou X, Song A (2015) Efficient agglomerative hierarchical clustering. Expert Systems with Applications 42:2785–2797. https://doi.org/<a href="https://doi.org/10.1016/j.eswa.2014.09.054">https://doi.org/10.1016/j.eswa.2014.09.054</a></div>
</div>
<div id="ref-Gilpin13" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">19. </div><div class="csl-right-inline">Gilpin S, Qian B, Davidson I (2013) <a href="https://doi.org/10.1145/2505515.2505527">Efficient hierarchical clustering of large high dimensional datasets</a>. In: Proceedings of the 22nd ACM international conference on information &amp; knowledge management. Association for Computing Machinery, New York, NY, USA, pp 1371–1380</div>
</div>
<div id="ref-Bringing" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">20. </div><div class="csl-right-inline">López-Pernas S, Saqr M (2021) Bringing synchrony and clarity to complex multi-channel data: A learning analytics study in programming education. IEEE Access 9:</div>
</div>
<div id="ref-Engagement" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">21. </div><div class="csl-right-inline">Saqr M, López-Pernas S (2021) The longitudinal trajectories of online engagement over a full program. Computers &amp; Education 175:104325</div>
</div>
<div id="ref-Matcha2020-jp" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">22. </div><div class="csl-right-inline">Matcha W, Gašević D, Ahmad Uzir N, Jovanović J, Pardo A, Lim L, Maldonado-Mahauad J, Gentili S, Pérez-Sanagustı́n M, Tsai Y-S (2020) Analytics of learning strategies: Role of course design and delivery modality. Journal of Learning Analytics 7:45–71. https://doi.org/<a href="https://doi.org/10.18608/jla.2020.72.3">10.18608/jla.2020.72.3</a></div>
</div>
<div id="ref-Peeters2020-wa" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">23. </div><div class="csl-right-inline">Peeters W, Saqr M, Viberg O (2020) Applying learning analytics to map students’ self-regulated learning tactics in an academic writing course. In: Proceedings of the 28th international conference on computers in education. pp 245–254</div>
</div>
<div id="ref-Lim2023-kg" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">24. </div><div class="csl-right-inline">Lim L, Bannert M, Graaf J van der, Singh S, Fan Y, Surendrannair S, Rakovic M, Molenaar I, Moore J, Gašević D (2023) Effects of real-time analytics-based personalized scaffolds on students’ self-regulated learning. Computers in Human Behavior 139:107547. https://doi.org/<a href="https://doi.org/10.1016/j.chb.2022.107547">10.1016/j.chb.2022.107547</a></div>
</div>
<div id="ref-Saqr2023-he" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">25. </div><div class="csl-right-inline">Saqr M, López-Pernas S (2023) The temporal dynamics of online problem-based learning: Why and when sequence matters. International Journal of Computer-Supported Collaborative Learning 18:11–37. https://doi.org/<a href="https://doi.org/10.1007/s11412-023-09385-1">10.1007/s11412-023-09385-1</a></div>
</div>
<div id="ref-Gatta2017-rg" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">26. </div><div class="csl-right-inline">Gatta R, Vallati M, Lenkowicz J, Rojas E, Damiani A, Sacchi L, De Bari B, Dagliati A, Fernandez-Llatas C, Montesi M, Marchetti A, Castellano M, Valentini V (2017) <a href="https://doi.org/10.1145/3148011.3154464">Generating and comparing knowledge graphs of medical processes using <span class="nocase">pMineR</span></a>. In: Proceedings of the knowledge capture conference. ACM, New York, NY, USA</div>
</div>
<div id="ref-Boroujeni2019-vf" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">27. </div><div class="csl-right-inline">Boroujeni MS, Dillenbourg P (2019) Discovery and temporal analysis of <span>MOOC</span> study patterns. Journal of Learning Analytics 6:16–33. https://doi.org/<a href="https://doi.org/10.18608/jla.2019.61.2">10.18608/jla.2019.61.2</a></div>
</div>
<div id="ref-Andrade2017-we" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">28. </div><div class="csl-right-inline">Andrade A, Danish JA, Maltese AV (2017) A measurement model of gestures in an embodied learning environment: Accounting for temporal dependencies. Journal of Learning Analytics 4:18–46. https://doi.org/<a href="https://doi.org/10.18608/jla.2017.43.3">10.18608/jla.2017.43.3</a></div>
</div>
<div id="ref-Kokoc2021-rc" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">29. </div><div class="csl-right-inline">Kokoç M, Akçapınar G, Hasnine MN (2021) <a href="https://www.jstor.org/stable/26977869">Unfolding students’ online assignment submission behavioral patterns using temporal learning analytics</a>. Educational Technology &amp; Society 24:223–235</div>
</div>
<div id="ref-qgraph" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">30. </div><div class="csl-right-inline">Epskamp S, Cramer AOJ, Waldorp LJ, Schmittmann VD, Borsboom D (2012) <span class="nocase">qgraph: network visualizations of relationships in psychometric data</span>. Journal of Statistical Software 48:</div>
</div>
<div id="ref-rio" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">31. </div><div class="csl-right-inline">Chan C, Chan GC, Leeper TJ, Becker J (2021) <span class="nocase">rio: a Swiss-army knife for data file I/O</span></div>
</div>
<div id="ref-seqHMM" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">32. </div><div class="csl-right-inline">Helske J, Helske S (2023) <a href="https://cran.r-project.org/package=seqHMM"><span class="nocase">seqHMM</span>: Mixture hidden <span>Markov</span> models for social sequence data and other multivariate, multichannel categorical time series</a></div>
</div>
<div id="ref-tidyverse" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">33. </div><div class="csl-right-inline">Wickham H, Averick M, Bryan J, Chang W, McGowan LD, François R, Grolemund G, Hayes A, Henry L, Hester J, Kuhn M, Pedersen TL, Miller E, Bache SM, Müller K, Ooms J, Robinson D, Seidel DP, Spinu V, Takahashi K, Vaughan D, Wilke C, Woo K, Yutani H (2019) Welcome to the <span class="nocase">tidyverse</span>. Journal of Open Source Software 4:1686. https://doi.org/<a href="https://doi.org/10.21105/joss.01686">10.21105/joss.01686</a></div>
</div>
<div id="ref-Gabadinho2011" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">34. </div><div class="csl-right-inline">Gabadinho A, Ritschard G, Müller NS, Studer M (2011) Analyzing and visualizing state sequences in <span>R</span> with <span>TraMineR</span>. Journal of Statistical Software 40: https://doi.org/<a href="https://doi.org/10.18637/jss.v040.i04">10.18637/jss.v040.i04</a></div>
</div>
<div id="ref-Satu" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">35. </div><div class="csl-right-inline">Saqr M, López-Pernas S, Helske S, Hrastinski S (2023) The longitudinal association between engagement and achievement varies by time, students’ profiles, and achievement state: A full program study. Computers &amp; Education 199:104787</div>
</div>
<div id="ref-SAQR2022104581" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">36. </div><div class="csl-right-inline">Saqr M, López-Pernas S (2022) How <span>CSCL</span> roles emerge, persist, transition, and evolve over time: A four-year longitudinal study. Computers &amp; Education 189:104581. https://doi.org/<a href="https://doi.org/10.1016/j.compedu.2022.104581">https://doi.org/10.1016/j.compedu.2022.104581</a></div>
</div>
<div id="ref-Helske2023" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">37. </div><div class="csl-right-inline">Helske S, Keski-Säntti M, Kivelä J, Juutinen A, Kääriälä A, Gissler M, Merikukka M, Lallukka T (2023) Predicting the stability of early employment with its timing and childhood social and health-related predictors: A mixture markov model approach. Longitudinal and Life Course Studies 14:73–104</div>
</div>
<div id="ref-peeters2020applying" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">38. </div><div class="csl-right-inline">Peeters W, Saqr M, Viberg O (2020) Applying learning analytics to map students’ self-regulated learning tactics in an academic writing course. In: Proceedings of the 28th international conference on computers in education. Asia-Pacific Society for Computers in Education, pp 245–254</div>
</div>
<div id="ref-saqr2022transferring" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">39. </div><div class="csl-right-inline">Saqr M, Matcha W, Jovanovic J, Gašević D, López-Pernas S, others (2022) Transferring effective learning strategies across learning contexts matters: A study in problem-based learning. Australasian Journal of Educational Technology 35–57</div>
</div>
<div id="ref-Lopez-Pernas2024-as" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">40. </div><div class="csl-right-inline">López-Pernas S, Saqr M (2024) The why, the how, and the when of educational process mining in <span>R</span>. In: Saqr M, López-Pernas S (eds) Learning analytics methods and tutorials: A practical guide using <span>R</span>. Springer, pp in–press</div>
</div>
<div id="ref-dynamitepaper" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">41. </div><div class="csl-right-inline">Tikka S, Helske J (2023) <a href="https://doi.org/10.48550/ARXIV.2302.01607"><span class="nocase">dynamite</span>: An <span>R</span> package for dynamic multivariate panel models</a></div>
</div>
<div id="ref-LMest" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">42. </div><div class="csl-right-inline">Bartolucci F, Pandolfi S, Pennoni F (2017) <span>LMest</span>: An <span>R</span> package for latent <span>M</span>arkov models for longitudinal categorical data. Journal of Statistical Software 81:1–38. https://doi.org/<a href="https://doi.org/10.18637/jss.v081.i04">10.18637/jss.v081.i04</a></div>
</div>
<div id="ref-latentgold" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">43. </div><div class="csl-right-inline">Vermunt JK, Magidson J (2016) <span class="nocase">Guide for Latent GOLD 5.1: Basic, Advanced, and Syntax</span>. Statistical Innovations Inc., Belmont, MA, U.S.A.</div>
</div>
<div id="ref-Berchtold" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">44. </div><div class="csl-right-inline">Berchtold A (1999) The double chain <span>M</span>arkov model. Communications in Statistics - Theory and Methods 28:2569–2589. https://doi.org/<a href="https://doi.org/10.1080/03610929908832439">10.1080/03610929908832439</a></div>
</div>
<div id="ref-march" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">45. </div><div class="csl-right-inline">Maitre O, Emery K, Oliver Buschor with contributions from, Berchtold A (2020) <a href="https://CRAN.R-project.org/package=march"><span class="nocase">march: Markov chains</span></a></div>
</div>
<div id="ref-Gabadinho2016" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">46. </div><div class="csl-right-inline">Gabadinho A, Ritschard G (2016) Analyzing state sequences with probabilistic suffix trees: The <span>PST</span> <span>R</span> package. Journal of Statistical Software 72:1–39. https://doi.org/<a href="https://doi.org/10.18637/jss.v072.i03">10.18637/jss.v072.i03</a></div>
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../chapters/ch11-vasstra/ch11-vasstra.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">VaSSTra</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../chapters/ch13-multichannel/ch13-multi.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Multi-channel sequences</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
      <div class="nav-footer-center"><div class="cookie-consent-footer"><a href="#" id="open_preferences_center">Cookie Preferences</a></div></div>
  </div>
</footer>
<script>
  document.querySelector(".quarto-title").innerHTML =  '<div class="badge bs-warning bg-warning text-dark" style="float:right;">Pre-print</div>' +  document.querySelector(".quarto-title").innerHTML
  var keywords = document.querySelector('meta[name="keywords"]')
  if (keywords && keywords.content) {
    document.getElementById("title-block-header").innerHTML = document.getElementById("title-block-header").innerHTML + 
      '<div class="abstract"><div class="abstract-title">Keywords</div><div class="quarto-title-meta-contents"><p>'+
      keywords.content +
      '</p></div></div>'
  }
</script>



</body></html>